{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "checkpoint = \"DeepWokLab/bert-tiny\"\n",
    "tokenizer_checkpoint = \"DeepWokLab/bert-tiny\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for DeepWokLab/bert-tiny.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads, inspired by the [NAS-BERT paper](https://arxiv.org/abs/2105.14444)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\": [\n",
    "        nn.Linear,\n",
    "        Identity,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_int` and `trial.suggest_categorical` functions to trigger the chosen sampler to choose parameter choices and layer types. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "    print(config)\n",
    "\n",
    "    # Update the paramaters in the config\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\",\n",
    "    ]:\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        print(f\"Chosen idx {chosen_idx} for param {param} ({len(search_space[param])})\")\n",
    "        setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "            print(\"DEBUG : \", new_layer_cls)\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-03 17:31:32,760] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"DeepWokLab/bert-tiny\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.48.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Chosen idx 0 for param num_layers (3)\n",
      "Chosen idx 1 for param num_heads (4)\n",
      "Chosen idx 3 for param hidden_size (5)\n",
      "Chosen idx 2 for param intermediate_size (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/dfouchard-21/mase/src/chop/tools/huggingface.py:158: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.341500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-03 17:35:46,631] Trial 0 finished with value: 0.8578 and parameters: {'num_layers': 0, 'num_heads': 1, 'hidden_size': 3, 'intermediate_size': 2, 'bert.encoder.layer.0.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.pooler.dense_type': <class 'chop.nn.modules.identity.Identity'>}. Best is trial 0 with value: 0.8578.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the model associated with the best trial as follows, and export to be used in future tutorials. In Tutorial 6, we'll see how to run mixed-precision quantization search on top of the model we've just found through NAS to further find the optimal quantization mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(f\"{Path.home()}/tutorial_5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Optimized Model with CompressionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the CompressionPipeline in Mase to run uniform quantization and pruning over the searched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for DeepWokLab/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-1.0191, -0.4146, -0.1004,  ..., -0.4698,  0.5287, -0.1453],\n",
      "         [-0.4490, -1.2138,  1.1871,  ..., -0.4330, -0.1595,  0.2291],\n",
      "         ...,\n",
      "         [-0.1101,  0.0914, -0.0169,  ..., -0.0791, -0.5381, -0.1931],\n",
      "         [ 0.3361, -0.7925, -0.2487,  ...,  1.5613,  0.2149,  0.8924],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]],\n",
      "\n",
      "        [[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-0.6474, -0.6419,  0.3303,  ..., -0.5007,  0.9504, -0.0963],\n",
      "         [-0.4455, -1.2327,  0.5406,  ..., -0.2969,  1.1258,  0.7185],\n",
      "         ...,\n",
      "         [-0.2316,  0.1960, -0.3915,  ..., -0.5674, -1.2436,  0.7239],\n",
      "         [ 0.5744,  0.1990, -0.8889,  ...,  0.0323, -0.1159,  0.5459],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-1.0191, -0.4146, -0.1004,  ..., -0.4698,  0.5287, -0.1453],\n",
      "         [-0.4490, -1.2138,  1.1871,  ..., -0.4330, -0.1595,  0.2291],\n",
      "         ...,\n",
      "         [-0.1101,  0.0914, -0.0169,  ..., -0.0791, -0.5381, -0.1931],\n",
      "         [ 0.3361, -0.7925, -0.2487,  ...,  1.5613,  0.2149,  0.8924],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]],\n",
      "\n",
      "        [[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-0.6474, -0.6419,  0.3303,  ..., -0.5007,  0.9504, -0.0963],\n",
      "         [-0.4455, -1.2327,  0.5406,  ..., -0.2969,  1.1258,  0.7185],\n",
      "         ...,\n",
      "         [-0.2316,  0.1960, -0.3915,  ..., -0.5674, -1.2436,  0.7239],\n",
      "         [ 0.5744,  0.1990, -0.8889,  ...,  0.0323, -0.1159,  0.5459],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-1.0191, -0.4146, -0.1004,  ..., -0.4698,  0.5287, -0.1453],\n",
      "         [-0.4490, -1.2138,  1.1871,  ..., -0.4330, -0.1595,  0.2291],\n",
      "         ...,\n",
      "         [-0.1101,  0.0914, -0.0169,  ..., -0.0791, -0.5381, -0.1931],\n",
      "         [ 0.3361, -0.7925, -0.2487,  ...,  1.5613,  0.2149,  0.8924],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]],\n",
      "\n",
      "        [[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-0.6474, -0.6419,  0.3303,  ..., -0.5007,  0.9504, -0.0963],\n",
      "         [-0.4455, -1.2327,  0.5406,  ..., -0.2969,  1.1258,  0.7185],\n",
      "         ...,\n",
      "         [-0.2316,  0.1960, -0.3915,  ..., -0.5674, -1.2436,  0.7239],\n",
      "         [ 0.5744,  0.1990, -0.8889,  ...,  0.0323, -0.1159,  0.5459],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 4.3003e-01,  2.6320e-01, -2.4554e-01,  ...,  7.6990e-01,\n",
      "           -2.1753e+00, -3.0483e-01],\n",
      "          [-1.6208e+00, -6.5670e-01,  6.3288e-02,  ...,  7.2053e-01,\n",
      "            7.3010e-01, -5.7709e-01]],\n",
      "\n",
      "         [[-1.0191e+00, -4.1458e-01, -1.0036e-01,  ...,  2.5379e+00,\n",
      "           -3.6248e-01,  1.0888e+00],\n",
      "          [-1.5182e+00,  1.6443e-01,  1.1671e+00,  ..., -4.6979e-01,\n",
      "            5.2872e-01, -1.4533e-01]],\n",
      "\n",
      "         [[-4.4899e-01, -1.2138e+00,  1.1871e+00,  ...,  1.7129e-01,\n",
      "           -1.5478e+00, -5.1657e-01],\n",
      "          [-4.3729e-02, -1.5445e-01, -8.0089e-01,  ..., -4.3299e-01,\n",
      "           -1.5946e-01,  2.2906e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1012e-01,  9.1431e-02, -1.6866e-02,  ...,  2.3330e-01,\n",
      "           -1.3747e+00, -3.7250e-01],\n",
      "          [-1.1842e+00, -1.0972e-02,  4.3484e-01,  ..., -7.9098e-02,\n",
      "           -5.3809e-01, -1.9313e-01]],\n",
      "\n",
      "         [[ 3.3614e-01, -7.9252e-01, -2.4873e-01,  ...,  5.9051e-01,\n",
      "           -9.2060e-01,  3.5203e-02],\n",
      "          [-3.4663e-01,  8.6673e-02, -6.5912e-01,  ...,  1.5613e+00,\n",
      "            2.1491e-01,  8.9236e-01]],\n",
      "\n",
      "         [[-3.1745e-01,  2.4009e-03,  2.2224e-01,  ...,  6.8467e-01,\n",
      "           -9.2021e-01, -1.1638e-01],\n",
      "          [-3.7794e-01, -2.2405e+00,  9.1381e-01,  ..., -2.6780e-01,\n",
      "            6.6240e-01,  1.1446e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3003e-01,  2.6320e-01, -2.4554e-01,  ...,  7.6990e-01,\n",
      "           -2.1753e+00, -3.0483e-01],\n",
      "          [-1.6208e+00, -6.5670e-01,  6.3288e-02,  ...,  7.2053e-01,\n",
      "            7.3010e-01, -5.7709e-01]],\n",
      "\n",
      "         [[-6.4744e-01, -6.4195e-01,  3.3030e-01,  ...,  8.1944e-01,\n",
      "           -1.2124e+00, -1.4623e-01],\n",
      "          [-2.6221e+00, -9.1413e-01,  1.3349e+00,  ..., -5.0070e-01,\n",
      "            9.5036e-01, -9.6285e-02]],\n",
      "\n",
      "         [[-4.4547e-01, -1.2327e+00,  5.4059e-01,  ..., -9.5327e-01,\n",
      "           -2.0425e+00, -9.7667e-01],\n",
      "          [-1.9137e-01, -2.6794e-01, -1.0548e-01,  ..., -2.9685e-01,\n",
      "            1.1258e+00,  7.1853e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3156e-01,  1.9598e-01, -3.9146e-01,  ..., -1.6279e+00,\n",
      "           -6.6425e-01, -1.0671e+00],\n",
      "          [-2.2240e+00,  3.0660e-01,  8.8498e-01,  ..., -5.6745e-01,\n",
      "           -1.2436e+00,  7.2390e-01]],\n",
      "\n",
      "         [[ 5.7443e-01,  1.9902e-01, -8.8895e-01,  ...,  1.3364e+00,\n",
      "           -3.5084e-01, -3.4948e-01],\n",
      "          [-9.0943e-01, -1.1324e+00, -1.8982e-01,  ...,  3.2343e-02,\n",
      "           -1.1588e-01,  5.4588e-01]],\n",
      "\n",
      "         [[-3.1745e-01,  2.4009e-03,  2.2224e-01,  ...,  6.8467e-01,\n",
      "           -9.2021e-01, -1.1638e-01],\n",
      "          [-3.7794e-01, -2.2405e+00,  9.1381e-01,  ..., -2.6780e-01,\n",
      "            6.6240e-01,  1.1446e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -3.6279e-01,\n",
      "          -2.5922e-01,  5.7339e-01],\n",
      "         [-3.5487e-01, -5.3361e-01,  1.9096e-01,  ..., -2.6150e-01,\n",
      "          -5.1831e-01, -2.6920e-01],\n",
      "         [ 2.0611e-01, -3.1262e-01,  3.8747e-01,  ...,  3.9793e-01,\n",
      "          -6.0547e-04,  7.1827e-02],\n",
      "         ...,\n",
      "         [ 1.1108e-01, -3.1741e-01,  3.8425e-02,  ..., -7.9089e-01,\n",
      "          -6.2264e-01,  5.2545e-01],\n",
      "         [-2.2540e-01, -4.9781e-01,  5.5971e-01,  ..., -3.1264e-01,\n",
      "          -3.1378e-02,  4.9624e-01],\n",
      "         [ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -2.1646e-01,\n",
      "          -4.8405e-01, -3.9321e-01]],\n",
      "\n",
      "        [[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -3.6279e-01,\n",
      "          -2.5922e-01,  5.7339e-01],\n",
      "         [-1.4037e-01, -8.2631e-01,  3.2254e-01,  ...,  3.0645e-01,\n",
      "          -2.5799e-01, -4.2961e-01],\n",
      "         [-6.3468e-01, -6.6192e-01, -3.5094e-02,  ...,  2.1638e-01,\n",
      "          -1.3844e-01, -3.7510e-02],\n",
      "         ...,\n",
      "         [-1.3120e-01, -8.8942e-02,  2.6323e-02,  ..., -7.7728e-01,\n",
      "          -7.5479e-01,  9.4814e-01],\n",
      "         [ 2.5498e-01,  2.7682e-01,  4.4705e-01,  ...,  4.4523e-02,\n",
      "          -5.0417e-01, -1.1870e-01],\n",
      "         [ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -2.1646e-01,\n",
      "          -4.8405e-01, -3.9321e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -3.6279e-01,\n",
      "          -2.5922e-01,  5.7339e-01],\n",
      "         [-3.5487e-01, -5.3361e-01,  1.9096e-01,  ..., -2.6150e-01,\n",
      "          -5.1831e-01, -2.6920e-01],\n",
      "         [ 2.0611e-01, -3.1262e-01,  3.8747e-01,  ...,  3.9793e-01,\n",
      "          -6.0547e-04,  7.1827e-02],\n",
      "         ...,\n",
      "         [ 1.1108e-01, -3.1741e-01,  3.8425e-02,  ..., -7.9089e-01,\n",
      "          -6.2264e-01,  5.2545e-01],\n",
      "         [-2.2540e-01, -4.9781e-01,  5.5971e-01,  ..., -3.1264e-01,\n",
      "          -3.1378e-02,  4.9624e-01],\n",
      "         [ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -2.1646e-01,\n",
      "          -4.8405e-01, -3.9321e-01]],\n",
      "\n",
      "        [[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -3.6279e-01,\n",
      "          -2.5922e-01,  5.7339e-01],\n",
      "         [-1.4037e-01, -8.2631e-01,  3.2254e-01,  ...,  3.0645e-01,\n",
      "          -2.5799e-01, -4.2961e-01],\n",
      "         [-6.3468e-01, -6.6192e-01, -3.5094e-02,  ...,  2.1638e-01,\n",
      "          -1.3844e-01, -3.7510e-02],\n",
      "         ...,\n",
      "         [-1.3120e-01, -8.8942e-02,  2.6323e-02,  ..., -7.7728e-01,\n",
      "          -7.5479e-01,  9.4814e-01],\n",
      "         [ 2.5498e-01,  2.7682e-01,  4.4705e-01,  ...,  4.4523e-02,\n",
      "          -5.0417e-01, -1.1870e-01],\n",
      "         [ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -2.1646e-01,\n",
      "          -4.8405e-01, -3.9321e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -5.4583e-01,\n",
      "            2.1505e-01,  3.8623e-01],\n",
      "          [ 5.3642e-01,  4.0585e-01, -1.8427e-01,  ..., -3.6279e-01,\n",
      "           -2.5922e-01,  5.7339e-01]],\n",
      "\n",
      "         [[-3.5487e-01, -5.3361e-01,  1.9096e-01,  ..., -8.4519e-01,\n",
      "           -6.5330e-02,  4.7102e-02],\n",
      "          [-1.2284e-01,  3.8221e-02, -1.5214e-01,  ..., -2.6150e-01,\n",
      "           -5.1831e-01, -2.6920e-01]],\n",
      "\n",
      "         [[ 2.0611e-01, -3.1262e-01,  3.8747e-01,  ..., -7.2026e-03,\n",
      "            3.8811e-01,  7.2714e-01],\n",
      "          [-1.1195e-01,  7.8406e-01,  7.2893e-02,  ...,  3.9793e-01,\n",
      "           -6.0547e-04,  7.1827e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1108e-01, -3.1741e-01,  3.8425e-02,  ..., -5.4469e-01,\n",
      "            5.3959e-01,  3.4868e-01],\n",
      "          [ 1.2069e+00,  4.8631e-01, -2.6262e-01,  ..., -7.9089e-01,\n",
      "           -6.2264e-01,  5.2545e-01]],\n",
      "\n",
      "         [[-2.2540e-01, -4.9781e-01,  5.5971e-01,  ..., -3.0025e-01,\n",
      "           -1.3658e-01,  3.9023e-01],\n",
      "          [-3.4555e-01,  1.3320e-01,  1.5211e-01,  ..., -3.1264e-01,\n",
      "           -3.1378e-02,  4.9624e-01]],\n",
      "\n",
      "         [[ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -3.7495e-01,\n",
      "            2.7322e-02,  4.4835e-01],\n",
      "          [ 1.6649e-02,  6.5796e-01, -4.7254e-01,  ..., -2.1646e-01,\n",
      "           -4.8405e-01, -3.9321e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6942e-02, -2.0949e-01,  7.2610e-01,  ..., -5.4583e-01,\n",
      "            2.1505e-01,  3.8623e-01],\n",
      "          [ 5.3642e-01,  4.0585e-01, -1.8427e-01,  ..., -3.6279e-01,\n",
      "           -2.5922e-01,  5.7339e-01]],\n",
      "\n",
      "         [[-1.4037e-01, -8.2631e-01,  3.2254e-01,  ..., -1.0046e+00,\n",
      "            1.9562e-01,  1.4808e-01],\n",
      "          [ 1.3017e-01, -7.0031e-02, -6.9638e-01,  ...,  3.0645e-01,\n",
      "           -2.5799e-01, -4.2961e-01]],\n",
      "\n",
      "         [[-6.3468e-01, -6.6192e-01, -3.5094e-02,  ..., -5.1251e-02,\n",
      "            4.5562e-01,  8.6138e-03],\n",
      "          [ 4.5712e-03,  1.0503e+00, -3.6521e-01,  ...,  2.1638e-01,\n",
      "           -1.3844e-01, -3.7510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3120e-01, -8.8942e-02,  2.6323e-02,  ..., -8.6755e-01,\n",
      "           -5.0493e-01,  9.4175e-01],\n",
      "          [ 7.5698e-01,  4.2321e-01,  8.4101e-02,  ..., -7.7728e-01,\n",
      "           -7.5479e-01,  9.4814e-01]],\n",
      "\n",
      "         [[ 2.5498e-01,  2.7682e-01,  4.4705e-01,  ..., -1.4241e-01,\n",
      "            1.4479e-01, -5.5495e-02],\n",
      "          [-3.2243e-01, -3.5324e-01,  4.5356e-01,  ...,  4.4523e-02,\n",
      "           -5.0417e-01, -1.1870e-01]],\n",
      "\n",
      "         [[ 2.0346e-01, -8.9732e-01,  3.6640e-01,  ..., -3.7495e-01,\n",
      "            2.7322e-02,  4.4835e-01],\n",
      "          [ 1.6649e-02,  6.5796e-01, -4.7254e-01,  ..., -2.1646e-01,\n",
      "           -4.8405e-01, -3.9321e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-1.0191, -0.4146, -0.1004,  ..., -0.4698,  0.5287, -0.1453],\n",
      "         [-0.4490, -1.2138,  1.1871,  ..., -0.4330, -0.1595,  0.2291],\n",
      "         ...,\n",
      "         [-0.1101,  0.0914, -0.0169,  ..., -0.0791, -0.5381, -0.1931],\n",
      "         [ 0.3361, -0.7925, -0.2487,  ...,  1.5613,  0.2149,  0.8924],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]],\n",
      "\n",
      "        [[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-0.6474, -0.6419,  0.3303,  ..., -0.5007,  0.9504, -0.0963],\n",
      "         [-0.4455, -1.2327,  0.5406,  ..., -0.2969,  1.1258,  0.7185],\n",
      "         ...,\n",
      "         [-0.2316,  0.1960, -0.3915,  ..., -0.5674, -1.2436,  0.7239],\n",
      "         [ 0.5744,  0.1990, -0.8889,  ...,  0.0323, -0.1159,  0.5459],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-1.0191, -0.4146, -0.1004,  ..., -0.4698,  0.5287, -0.1453],\n",
      "         [-0.4490, -1.2138,  1.1871,  ..., -0.4330, -0.1595,  0.2291],\n",
      "         ...,\n",
      "         [-0.1101,  0.0914, -0.0169,  ..., -0.0791, -0.5381, -0.1931],\n",
      "         [ 0.3361, -0.7925, -0.2487,  ...,  1.5613,  0.2149,  0.8924],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]],\n",
      "\n",
      "        [[ 0.4300,  0.2632, -0.2455,  ...,  0.7205,  0.7301, -0.5771],\n",
      "         [-0.6474, -0.6419,  0.3303,  ..., -0.5007,  0.9504, -0.0963],\n",
      "         [-0.4455, -1.2327,  0.5406,  ..., -0.2969,  1.1258,  0.7185],\n",
      "         ...,\n",
      "         [-0.2316,  0.1960, -0.3915,  ..., -0.5674, -1.2436,  0.7239],\n",
      "         [ 0.5744,  0.1990, -0.8889,  ...,  0.0323, -0.1159,  0.5459],\n",
      "         [-0.3175,  0.0024,  0.2222,  ..., -0.2678,  0.6624,  0.1145]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 4.3003e-01,  2.6320e-01, -2.4554e-01,  ...,  7.6990e-01,\n",
      "           -2.1753e+00, -3.0483e-01],\n",
      "          [-1.6208e+00, -6.5670e-01,  6.3288e-02,  ...,  7.2053e-01,\n",
      "            7.3010e-01, -5.7709e-01]],\n",
      "\n",
      "         [[-1.0191e+00, -4.1458e-01, -1.0036e-01,  ...,  2.5379e+00,\n",
      "           -3.6248e-01,  1.0888e+00],\n",
      "          [-1.5182e+00,  1.6443e-01,  1.1671e+00,  ..., -4.6979e-01,\n",
      "            5.2872e-01, -1.4533e-01]],\n",
      "\n",
      "         [[-4.4899e-01, -1.2138e+00,  1.1871e+00,  ...,  1.7129e-01,\n",
      "           -1.5478e+00, -5.1657e-01],\n",
      "          [-4.3729e-02, -1.5445e-01, -8.0089e-01,  ..., -4.3299e-01,\n",
      "           -1.5946e-01,  2.2906e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1012e-01,  9.1431e-02, -1.6866e-02,  ...,  2.3330e-01,\n",
      "           -1.3747e+00, -3.7250e-01],\n",
      "          [-1.1842e+00, -1.0972e-02,  4.3484e-01,  ..., -7.9098e-02,\n",
      "           -5.3809e-01, -1.9313e-01]],\n",
      "\n",
      "         [[ 3.3614e-01, -7.9252e-01, -2.4873e-01,  ...,  5.9051e-01,\n",
      "           -9.2060e-01,  3.5203e-02],\n",
      "          [-3.4663e-01,  8.6673e-02, -6.5912e-01,  ...,  1.5613e+00,\n",
      "            2.1491e-01,  8.9236e-01]],\n",
      "\n",
      "         [[-3.1745e-01,  2.4009e-03,  2.2224e-01,  ...,  6.8467e-01,\n",
      "           -9.2021e-01, -1.1638e-01],\n",
      "          [-3.7794e-01, -2.2405e+00,  9.1381e-01,  ..., -2.6780e-01,\n",
      "            6.6240e-01,  1.1446e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3003e-01,  2.6320e-01, -2.4554e-01,  ...,  7.6990e-01,\n",
      "           -2.1753e+00, -3.0483e-01],\n",
      "          [-1.6208e+00, -6.5670e-01,  6.3288e-02,  ...,  7.2053e-01,\n",
      "            7.3010e-01, -5.7709e-01]],\n",
      "\n",
      "         [[-6.4744e-01, -6.4195e-01,  3.3030e-01,  ...,  8.1944e-01,\n",
      "           -1.2124e+00, -1.4623e-01],\n",
      "          [-2.6221e+00, -9.1413e-01,  1.3349e+00,  ..., -5.0070e-01,\n",
      "            9.5036e-01, -9.6285e-02]],\n",
      "\n",
      "         [[-4.4547e-01, -1.2327e+00,  5.4059e-01,  ..., -9.5327e-01,\n",
      "           -2.0425e+00, -9.7667e-01],\n",
      "          [-1.9137e-01, -2.6794e-01, -1.0548e-01,  ..., -2.9685e-01,\n",
      "            1.1258e+00,  7.1853e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3156e-01,  1.9598e-01, -3.9146e-01,  ..., -1.6279e+00,\n",
      "           -6.6425e-01, -1.0671e+00],\n",
      "          [-2.2240e+00,  3.0660e-01,  8.8498e-01,  ..., -5.6745e-01,\n",
      "           -1.2436e+00,  7.2390e-01]],\n",
      "\n",
      "         [[ 5.7443e-01,  1.9902e-01, -8.8895e-01,  ...,  1.3364e+00,\n",
      "           -3.5084e-01, -3.4948e-01],\n",
      "          [-9.0943e-01, -1.1324e+00, -1.8982e-01,  ...,  3.2343e-02,\n",
      "           -1.1588e-01,  5.4588e-01]],\n",
      "\n",
      "         [[-3.1745e-01,  2.4009e-03,  2.2224e-01,  ...,  6.8467e-01,\n",
      "           -9.2021e-01, -1.1638e-01],\n",
      "          [-3.7794e-01, -2.2405e+00,  9.1381e-01,  ..., -2.6780e-01,\n",
      "            6.6240e-01,  1.1446e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-3.5231e-01, -2.0833e-01,  4.7904e-01,  ...,  1.1844e+00,\n",
      "           -7.9783e-01,  1.2862e-01],\n",
      "          [-1.0016e-03, -1.8452e-01,  5.6678e-01,  ...,  1.1668e+00,\n",
      "           -8.1858e-01,  9.9910e-02],\n",
      "          [-3.3285e-01, -3.0114e-01,  4.9159e-01,  ...,  1.1087e+00,\n",
      "           -1.0132e+00,  3.0015e-01],\n",
      "          ...,\n",
      "          [-1.1983e-01, -2.6051e-01,  5.7775e-01,  ...,  1.0545e+00,\n",
      "           -9.3199e-01,  1.1522e-01],\n",
      "          [-1.1168e-01, -2.0633e-01,  5.1497e-01,  ...,  1.0942e+00,\n",
      "           -9.0431e-01,  8.5086e-02],\n",
      "          [-8.6326e-02, -2.9444e-01,  6.1160e-01,  ...,  9.1177e-01,\n",
      "           -1.1090e+00,  1.7751e-01]],\n",
      "\n",
      "         [[-9.8344e-01, -4.5442e-01,  1.6903e+00,  ...,  4.7129e-01,\n",
      "           -4.3113e-01,  3.7592e-01],\n",
      "          [-8.3803e-01, -3.8675e-01,  8.1520e-01,  ...,  3.5446e-01,\n",
      "            5.4608e-02,  2.0890e-01],\n",
      "          [-9.3502e-01, -4.6213e-01,  1.1510e+00,  ...,  3.7444e-01,\n",
      "           -5.3146e-02,  2.0694e-01],\n",
      "          ...,\n",
      "          [-8.3833e-01, -4.9246e-01,  1.2944e+00,  ...,  4.5493e-01,\n",
      "           -2.2992e-01,  3.0834e-01],\n",
      "          [-8.7186e-01, -4.9921e-01,  1.2427e+00,  ...,  3.4495e-01,\n",
      "           -1.3781e-01,  2.1430e-01],\n",
      "          [-8.2827e-01, -4.1796e-01,  1.0459e+00,  ...,  4.4843e-01,\n",
      "           -9.7104e-02,  2.7205e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8234e-01, -2.1361e-01, -2.1095e-01,  ...,  1.0857e+00,\n",
      "           -4.4590e-01, -3.1394e-01],\n",
      "          [-1.6401e-01,  2.6133e-03,  2.1820e-01,  ...,  9.6052e-01,\n",
      "           -6.8878e-01, -5.0021e-02],\n",
      "          [-2.5763e-01,  3.6842e-02,  2.3384e-01,  ...,  8.9882e-01,\n",
      "           -7.2475e-01, -1.7192e-02],\n",
      "          ...,\n",
      "          [-1.8494e-01, -3.5997e-02,  3.4172e-01,  ...,  8.4447e-01,\n",
      "           -6.5905e-01, -1.0984e-01],\n",
      "          [-2.1739e-01, -4.2015e-02, -8.3072e-03,  ...,  9.2157e-01,\n",
      "           -7.6053e-01, -2.1250e-01],\n",
      "          [-7.8415e-02,  2.6683e-02,  4.2008e-01,  ...,  7.6994e-01,\n",
      "           -8.1694e-01,  5.5612e-04]],\n",
      "\n",
      "         [[-9.5070e-01, -3.4767e-01,  5.7209e-01,  ...,  6.4366e-01,\n",
      "            4.7350e-01,  3.3789e-02],\n",
      "          [-1.0570e+00, -3.8954e-01,  5.2154e-01,  ...,  3.9882e-01,\n",
      "            3.6243e-01,  5.7571e-02],\n",
      "          [-1.0263e+00, -4.5558e-01,  5.2381e-01,  ...,  4.2272e-01,\n",
      "            4.6757e-01,  2.0310e-02],\n",
      "          ...,\n",
      "          [-9.9627e-01, -5.0749e-01,  6.5579e-01,  ...,  6.7054e-01,\n",
      "            4.5725e-01,  3.3510e-02],\n",
      "          [-1.0595e+00, -4.9997e-01,  5.3897e-01,  ...,  4.7409e-01,\n",
      "            5.0816e-01,  1.3721e-02],\n",
      "          [-1.0617e+00, -6.0450e-01,  5.4466e-01,  ...,  4.4844e-01,\n",
      "            3.1588e-01,  8.2895e-02]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-3.5231e-01, -2.0833e-01,  4.7904e-01,  ...,  1.1844e+00,\n",
      "           -7.9783e-01,  1.2862e-01],\n",
      "          [-9.8344e-01, -4.5442e-01,  1.6903e+00,  ...,  4.7129e-01,\n",
      "           -4.3113e-01,  3.7592e-01]],\n",
      "\n",
      "         [[-1.0016e-03, -1.8452e-01,  5.6678e-01,  ...,  1.1668e+00,\n",
      "           -8.1858e-01,  9.9910e-02],\n",
      "          [-8.3803e-01, -3.8675e-01,  8.1520e-01,  ...,  3.5446e-01,\n",
      "            5.4608e-02,  2.0890e-01]],\n",
      "\n",
      "         [[-3.3285e-01, -3.0114e-01,  4.9159e-01,  ...,  1.1087e+00,\n",
      "           -1.0132e+00,  3.0015e-01],\n",
      "          [-9.3502e-01, -4.6213e-01,  1.1510e+00,  ...,  3.7444e-01,\n",
      "           -5.3146e-02,  2.0694e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1983e-01, -2.6051e-01,  5.7775e-01,  ...,  1.0545e+00,\n",
      "           -9.3199e-01,  1.1522e-01],\n",
      "          [-8.3833e-01, -4.9246e-01,  1.2944e+00,  ...,  4.5493e-01,\n",
      "           -2.2992e-01,  3.0834e-01]],\n",
      "\n",
      "         [[-1.1168e-01, -2.0633e-01,  5.1497e-01,  ...,  1.0942e+00,\n",
      "           -9.0431e-01,  8.5086e-02],\n",
      "          [-8.7186e-01, -4.9921e-01,  1.2427e+00,  ...,  3.4495e-01,\n",
      "           -1.3781e-01,  2.1430e-01]],\n",
      "\n",
      "         [[-8.6326e-02, -2.9444e-01,  6.1160e-01,  ...,  9.1177e-01,\n",
      "           -1.1090e+00,  1.7751e-01],\n",
      "          [-8.2827e-01, -4.1796e-01,  1.0459e+00,  ...,  4.4843e-01,\n",
      "           -9.7104e-02,  2.7205e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8234e-01, -2.1361e-01, -2.1095e-01,  ...,  1.0857e+00,\n",
      "           -4.4590e-01, -3.1394e-01],\n",
      "          [-9.5070e-01, -3.4767e-01,  5.7209e-01,  ...,  6.4366e-01,\n",
      "            4.7350e-01,  3.3789e-02]],\n",
      "\n",
      "         [[-1.6401e-01,  2.6133e-03,  2.1820e-01,  ...,  9.6052e-01,\n",
      "           -6.8878e-01, -5.0021e-02],\n",
      "          [-1.0570e+00, -3.8954e-01,  5.2154e-01,  ...,  3.9882e-01,\n",
      "            3.6243e-01,  5.7571e-02]],\n",
      "\n",
      "         [[-2.5763e-01,  3.6842e-02,  2.3384e-01,  ...,  8.9882e-01,\n",
      "           -7.2475e-01, -1.7192e-02],\n",
      "          [-1.0263e+00, -4.5558e-01,  5.2381e-01,  ...,  4.2272e-01,\n",
      "            4.6757e-01,  2.0310e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8494e-01, -3.5997e-02,  3.4172e-01,  ...,  8.4447e-01,\n",
      "           -6.5905e-01, -1.0984e-01],\n",
      "          [-9.9627e-01, -5.0749e-01,  6.5579e-01,  ...,  6.7054e-01,\n",
      "            4.5725e-01,  3.3510e-02]],\n",
      "\n",
      "         [[-2.1739e-01, -4.2015e-02, -8.3072e-03,  ...,  9.2157e-01,\n",
      "           -7.6053e-01, -2.1250e-01],\n",
      "          [-1.0595e+00, -4.9997e-01,  5.3897e-01,  ...,  4.7409e-01,\n",
      "            5.0816e-01,  1.3721e-02]],\n",
      "\n",
      "         [[-7.8415e-02,  2.6683e-02,  4.2008e-01,  ...,  7.6994e-01,\n",
      "           -8.1694e-01,  5.5612e-04],\n",
      "          [-1.0617e+00, -6.0450e-01,  5.4466e-01,  ...,  4.4844e-01,\n",
      "            3.1588e-01,  8.2895e-02]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.0888,  0.0107,  0.1615,  ...,  0.9728,  0.0436,  0.0086],\n",
      "         [-0.6245, -0.6065,  0.3697,  ..., -0.0396, -0.0795,  0.0912],\n",
      "         [-0.1810, -1.3232,  1.0977,  ...,  0.1442, -0.5278,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0125, -0.5018,  0.3203,  ...,  0.4258, -0.8856,  0.2323],\n",
      "         [ 0.5430, -0.8630,  0.1137,  ...,  1.5963, -0.3229,  0.9256],\n",
      "         [ 0.0152, -0.3900,  0.6494,  ...,  0.3073,  0.0111,  0.5132]],\n",
      "\n",
      "        [[-0.0611,  0.1802, -0.1886,  ...,  1.1669,  0.9655, -0.2765],\n",
      "         [-0.4721, -0.4356,  0.5253,  ...,  0.0753,  1.0696, -0.0117],\n",
      "         [-0.1271, -1.0437,  0.5605,  ...,  0.3948,  0.9543,  0.6109],\n",
      "         ...,\n",
      "         [-0.0557, -0.0518, -0.0417,  ...,  0.2706, -0.8837,  0.7347],\n",
      "         [ 0.4764,  0.1626, -0.4622,  ...,  0.5294,  0.3219,  0.4510],\n",
      "         [-0.0318, -0.0277,  0.5782,  ...,  0.3076,  0.4758,  0.4056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.0888,  0.0107,  0.1615,  ...,  0.9728,  0.0436,  0.0086],\n",
      "         [-0.6245, -0.6065,  0.3697,  ..., -0.0396, -0.0795,  0.0912],\n",
      "         [-0.1810, -1.3232,  1.0977,  ...,  0.1442, -0.5278,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0125, -0.5018,  0.3203,  ...,  0.4258, -0.8856,  0.2323],\n",
      "         [ 0.5430, -0.8630,  0.1137,  ...,  1.5963, -0.3229,  0.9256],\n",
      "         [ 0.0152, -0.3900,  0.6494,  ...,  0.3073,  0.0111,  0.5132]],\n",
      "\n",
      "        [[-0.0611,  0.1802, -0.1886,  ...,  1.1669,  0.9655, -0.2765],\n",
      "         [-0.4721, -0.4356,  0.5253,  ...,  0.0753,  1.0696, -0.0117],\n",
      "         [-0.1271, -1.0437,  0.5605,  ...,  0.3948,  0.9543,  0.6109],\n",
      "         ...,\n",
      "         [-0.0557, -0.0518, -0.0417,  ...,  0.2706, -0.8837,  0.7347],\n",
      "         [ 0.4764,  0.1626, -0.4622,  ...,  0.5294,  0.3219,  0.4510],\n",
      "         [-0.0318, -0.0277,  0.5782,  ...,  0.3076,  0.4758,  0.4056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.0888,  0.0107,  0.1615,  ...,  0.9728,  0.0436,  0.0086],\n",
      "         [-0.6245, -0.6065,  0.3697,  ..., -0.0396, -0.0795,  0.0912],\n",
      "         [-0.1810, -1.3232,  1.0977,  ...,  0.1442, -0.5278,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0125, -0.5018,  0.3203,  ...,  0.4258, -0.8856,  0.2323],\n",
      "         [ 0.5430, -0.8630,  0.1137,  ...,  1.5963, -0.3229,  0.9256],\n",
      "         [ 0.0152, -0.3900,  0.6494,  ...,  0.3073,  0.0111,  0.5132]],\n",
      "\n",
      "        [[-0.0611,  0.1802, -0.1886,  ...,  1.1669,  0.9655, -0.2765],\n",
      "         [-0.4721, -0.4356,  0.5253,  ...,  0.0753,  1.0696, -0.0117],\n",
      "         [-0.1271, -1.0437,  0.5605,  ...,  0.3948,  0.9543,  0.6109],\n",
      "         ...,\n",
      "         [-0.0557, -0.0518, -0.0417,  ...,  0.2706, -0.8837,  0.7347],\n",
      "         [ 0.4764,  0.1626, -0.4622,  ...,  0.5294,  0.3219,  0.4510],\n",
      "         [-0.0318, -0.0277,  0.5782,  ...,  0.3076,  0.4758,  0.4056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.0888,  0.0107,  0.1615,  ...,  0.9608, -2.1885,  0.1424],\n",
      "          [-2.1078, -0.5942,  1.0903,  ...,  0.9728,  0.0436,  0.0086]],\n",
      "\n",
      "         [[-0.6245, -0.6065,  0.3697,  ...,  2.3487, -0.8903,  0.9134],\n",
      "          [-1.7687,  0.0272,  1.3701,  ..., -0.0396, -0.0795,  0.0912]],\n",
      "\n",
      "         [[-0.1810, -1.3232,  1.0977,  ...,  0.6358, -1.8520,  0.0196],\n",
      "          [-1.0108, -0.2407,  0.0359,  ...,  0.1442, -0.5278,  0.3332]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0125, -0.5018,  0.3203,  ...,  0.2709, -1.7058, -0.1080],\n",
      "          [-1.6802, -0.1157,  1.0593,  ...,  0.4258, -0.8856,  0.2323]],\n",
      "\n",
      "         [[ 0.5430, -0.8630,  0.1137,  ...,  0.7724, -1.3581,  0.3583],\n",
      "          [-0.9439,  0.0108,  0.0796,  ...,  1.5963, -0.3229,  0.9256]],\n",
      "\n",
      "         [[ 0.0152, -0.3900,  0.6494,  ...,  0.7428, -1.5218,  0.1127],\n",
      "          [-0.9420, -1.7685,  1.3053,  ...,  0.3073,  0.0111,  0.5132]]],\n",
      "\n",
      "\n",
      "        [[[-0.0611,  0.1802, -0.1886,  ...,  1.0459, -2.0105, -0.1077],\n",
      "          [-2.1802, -0.5542,  0.3837,  ...,  1.1669,  0.9655, -0.2765]],\n",
      "\n",
      "         [[-0.4721, -0.4356,  0.5253,  ...,  1.0456, -1.4184,  0.1359],\n",
      "          [-2.8943, -0.7459,  1.2364,  ...,  0.0753,  1.0696, -0.0117]],\n",
      "\n",
      "         [[-0.1271, -1.0437,  0.5605,  ..., -0.4282, -2.0243, -0.5678],\n",
      "          [-1.3276, -0.2824,  0.1829,  ...,  0.3948,  0.9543,  0.6109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0557, -0.0518, -0.0417,  ..., -1.2806, -1.0130, -0.8040],\n",
      "          [-2.5002,  0.1073,  0.9734,  ...,  0.2706, -0.8837,  0.7347]],\n",
      "\n",
      "         [[ 0.4764,  0.1626, -0.4622,  ...,  1.5771, -0.9164, -0.1335],\n",
      "          [-1.6711, -0.9129, -0.0746,  ...,  0.5294,  0.3219,  0.4510]],\n",
      "\n",
      "         [[-0.0318, -0.0277,  0.5782,  ...,  0.7000, -1.2813,  0.0404],\n",
      "          [-1.1054, -1.9300,  0.9404,  ...,  0.3076,  0.4758,  0.4056]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0267,  0.0311,  1.0764,  ..., -0.3369, -0.3981,  0.1986],\n",
      "         [ 0.0013, -0.3059,  0.6433,  ..., -0.2645, -0.3226,  0.2068],\n",
      "         [-0.2120, -0.2739,  0.7224,  ..., -0.2833, -0.1271,  0.2301],\n",
      "         ...,\n",
      "         [ 0.2631, -0.4623,  1.1783,  ..., -0.2167, -0.5930,  0.7732],\n",
      "         [-0.0648,  0.0013,  0.7681,  ..., -0.4676, -0.2351,  0.0586],\n",
      "         [ 0.3007,  0.4490,  0.6999,  ..., -0.4918, -0.5556,  0.7778]],\n",
      "\n",
      "        [[ 0.1807,  0.2806,  1.2235,  ..., -0.2842, -0.0945,  0.2138],\n",
      "         [-0.0195,  0.3068,  0.5395,  ..., -0.3027, -0.5316,  0.1181],\n",
      "         [-0.3203,  0.2893,  0.8529,  ...,  0.0017, -0.1693,  0.7792],\n",
      "         ...,\n",
      "         [-0.2361,  0.2258,  1.2862,  ...,  0.0805, -0.5729,  0.8405],\n",
      "         [ 0.2320,  0.3989,  0.3441,  ..., -0.7031,  0.0319,  0.1232],\n",
      "         [ 0.4650,  0.6502,  0.7183,  ..., -0.4675, -0.4323,  0.7308]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0267,  0.0311,  1.0764,  ..., -0.3369, -0.3981,  0.1986],\n",
      "         [ 0.0013, -0.3059,  0.6433,  ..., -0.2645, -0.3226,  0.2068],\n",
      "         [-0.2120, -0.2739,  0.7224,  ..., -0.2833, -0.1271,  0.2301],\n",
      "         ...,\n",
      "         [ 0.2631, -0.4623,  1.1783,  ..., -0.2167, -0.5930,  0.7732],\n",
      "         [-0.0648,  0.0013,  0.7681,  ..., -0.4676, -0.2351,  0.0586],\n",
      "         [ 0.3007,  0.4490,  0.6999,  ..., -0.4918, -0.5556,  0.7778]],\n",
      "\n",
      "        [[ 0.1807,  0.2806,  1.2235,  ..., -0.2842, -0.0945,  0.2138],\n",
      "         [-0.0195,  0.3068,  0.5395,  ..., -0.3027, -0.5316,  0.1181],\n",
      "         [-0.3203,  0.2893,  0.8529,  ...,  0.0017, -0.1693,  0.7792],\n",
      "         ...,\n",
      "         [-0.2361,  0.2258,  1.2862,  ...,  0.0805, -0.5729,  0.8405],\n",
      "         [ 0.2320,  0.3989,  0.3441,  ..., -0.7031,  0.0319,  0.1232],\n",
      "         [ 0.4650,  0.6502,  0.7183,  ..., -0.4675, -0.4323,  0.7308]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0267,  0.0311,  1.0764,  ...,  0.0209,  0.5914, -0.5251],\n",
      "          [ 0.6481, -0.0500,  0.2511,  ..., -0.3369, -0.3981,  0.1986]],\n",
      "\n",
      "         [[ 0.0013, -0.3059,  0.6433,  ..., -0.7111,  0.4696, -0.6920],\n",
      "          [ 0.2363, -0.2174, -0.0138,  ..., -0.2645, -0.3226,  0.2068]],\n",
      "\n",
      "         [[-0.2120, -0.2739,  0.7224,  ..., -0.4517,  0.1234, -0.7068],\n",
      "          [ 0.3384, -0.1584,  0.4257,  ..., -0.2833, -0.1271,  0.2301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2631, -0.4623,  1.1783,  ..., -0.3052,  0.7159, -0.2695],\n",
      "          [ 0.9509, -0.2262,  0.1677,  ..., -0.2167, -0.5930,  0.7732]],\n",
      "\n",
      "         [[-0.0648,  0.0013,  0.7681,  ..., -0.6200,  0.4698, -0.2713],\n",
      "          [ 0.1948, -0.1028,  0.4572,  ..., -0.4676, -0.2351,  0.0586]],\n",
      "\n",
      "         [[ 0.3007,  0.4490,  0.6999,  ..., -0.3584,  0.4478, -0.2341],\n",
      "          [ 0.2634,  0.4210,  0.0764,  ..., -0.4918, -0.5556,  0.7778]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1807,  0.2806,  1.2235,  ...,  0.0378,  0.7535, -0.5433],\n",
      "          [ 0.4158,  0.2309,  0.4287,  ..., -0.2842, -0.0945,  0.2138]],\n",
      "\n",
      "         [[-0.0195,  0.3068,  0.5395,  ..., -0.7020,  0.4533, -0.8574],\n",
      "          [ 0.2492,  0.0907,  0.3063,  ..., -0.3027, -0.5316,  0.1181]],\n",
      "\n",
      "         [[-0.3203,  0.2893,  0.8529,  ..., -0.5307, -0.0059, -0.7639],\n",
      "          [-0.1308,  0.2863,  0.6637,  ...,  0.0017, -0.1693,  0.7792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2361,  0.2258,  1.2862,  ..., -0.1808,  0.4215, -0.5640],\n",
      "          [ 0.9134,  0.2516,  0.3489,  ...,  0.0805, -0.5729,  0.8405]],\n",
      "\n",
      "         [[ 0.2320,  0.3989,  0.3441,  ..., -0.3650,  0.2713, -0.3803],\n",
      "          [-0.0712,  0.0527,  0.5054,  ..., -0.7031,  0.0319,  0.1232]],\n",
      "\n",
      "         [[ 0.4650,  0.6502,  0.7183,  ..., -0.4418,  0.5133, -0.2687],\n",
      "          [ 0.0956,  0.6421,  0.1421,  ..., -0.4675, -0.4323,  0.7308]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0888,  0.0107,  0.1615,  ...,  0.9728,  0.0436,  0.0086],\n",
      "         [-0.6245, -0.6065,  0.3697,  ..., -0.0396, -0.0795,  0.0912],\n",
      "         [-0.1810, -1.3232,  1.0977,  ...,  0.1442, -0.5278,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0125, -0.5018,  0.3203,  ...,  0.4258, -0.8856,  0.2323],\n",
      "         [ 0.5430, -0.8630,  0.1137,  ...,  1.5963, -0.3229,  0.9256],\n",
      "         [ 0.0152, -0.3900,  0.6494,  ...,  0.3073,  0.0111,  0.5132]],\n",
      "\n",
      "        [[-0.0611,  0.1802, -0.1886,  ...,  1.1669,  0.9655, -0.2765],\n",
      "         [-0.4721, -0.4356,  0.5253,  ...,  0.0753,  1.0696, -0.0117],\n",
      "         [-0.1271, -1.0437,  0.5605,  ...,  0.3948,  0.9543,  0.6109],\n",
      "         ...,\n",
      "         [-0.0557, -0.0518, -0.0417,  ...,  0.2706, -0.8837,  0.7347],\n",
      "         [ 0.4764,  0.1626, -0.4622,  ...,  0.5294,  0.3219,  0.4510],\n",
      "         [-0.0318, -0.0277,  0.5782,  ...,  0.3076,  0.4758,  0.4056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.0888,  0.0107,  0.1615,  ...,  0.9728,  0.0436,  0.0086],\n",
      "         [-0.6245, -0.6065,  0.3697,  ..., -0.0396, -0.0795,  0.0912],\n",
      "         [-0.1810, -1.3232,  1.0977,  ...,  0.1442, -0.5278,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0125, -0.5018,  0.3203,  ...,  0.4258, -0.8856,  0.2323],\n",
      "         [ 0.5430, -0.8630,  0.1137,  ...,  1.5963, -0.3229,  0.9256],\n",
      "         [ 0.0152, -0.3900,  0.6494,  ...,  0.3073,  0.0111,  0.5132]],\n",
      "\n",
      "        [[-0.0611,  0.1802, -0.1886,  ...,  1.1669,  0.9655, -0.2765],\n",
      "         [-0.4721, -0.4356,  0.5253,  ...,  0.0753,  1.0696, -0.0117],\n",
      "         [-0.1271, -1.0437,  0.5605,  ...,  0.3948,  0.9543,  0.6109],\n",
      "         ...,\n",
      "         [-0.0557, -0.0518, -0.0417,  ...,  0.2706, -0.8837,  0.7347],\n",
      "         [ 0.4764,  0.1626, -0.4622,  ...,  0.5294,  0.3219,  0.4510],\n",
      "         [-0.0318, -0.0277,  0.5782,  ...,  0.3076,  0.4758,  0.4056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.0888,  0.0107,  0.1615,  ...,  0.9608, -2.1885,  0.1424],\n",
      "          [-2.1078, -0.5942,  1.0903,  ...,  0.9728,  0.0436,  0.0086]],\n",
      "\n",
      "         [[-0.6245, -0.6065,  0.3697,  ...,  2.3487, -0.8903,  0.9134],\n",
      "          [-1.7687,  0.0272,  1.3701,  ..., -0.0396, -0.0795,  0.0912]],\n",
      "\n",
      "         [[-0.1810, -1.3232,  1.0977,  ...,  0.6358, -1.8520,  0.0196],\n",
      "          [-1.0108, -0.2407,  0.0359,  ...,  0.1442, -0.5278,  0.3332]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0125, -0.5018,  0.3203,  ...,  0.2709, -1.7058, -0.1080],\n",
      "          [-1.6802, -0.1157,  1.0593,  ...,  0.4258, -0.8856,  0.2323]],\n",
      "\n",
      "         [[ 0.5430, -0.8630,  0.1137,  ...,  0.7724, -1.3581,  0.3583],\n",
      "          [-0.9439,  0.0108,  0.0796,  ...,  1.5963, -0.3229,  0.9256]],\n",
      "\n",
      "         [[ 0.0152, -0.3900,  0.6494,  ...,  0.7428, -1.5218,  0.1127],\n",
      "          [-0.9420, -1.7685,  1.3053,  ...,  0.3073,  0.0111,  0.5132]]],\n",
      "\n",
      "\n",
      "        [[[-0.0611,  0.1802, -0.1886,  ...,  1.0459, -2.0105, -0.1077],\n",
      "          [-2.1802, -0.5542,  0.3837,  ...,  1.1669,  0.9655, -0.2765]],\n",
      "\n",
      "         [[-0.4721, -0.4356,  0.5253,  ...,  1.0456, -1.4184,  0.1359],\n",
      "          [-2.8943, -0.7459,  1.2364,  ...,  0.0753,  1.0696, -0.0117]],\n",
      "\n",
      "         [[-0.1271, -1.0437,  0.5605,  ..., -0.4282, -2.0243, -0.5678],\n",
      "          [-1.3276, -0.2824,  0.1829,  ...,  0.3948,  0.9543,  0.6109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0557, -0.0518, -0.0417,  ..., -1.2806, -1.0130, -0.8040],\n",
      "          [-2.5002,  0.1073,  0.9734,  ...,  0.2706, -0.8837,  0.7347]],\n",
      "\n",
      "         [[ 0.4764,  0.1626, -0.4622,  ...,  1.5771, -0.9164, -0.1335],\n",
      "          [-1.6711, -0.9129, -0.0746,  ...,  0.5294,  0.3219,  0.4510]],\n",
      "\n",
      "         [[-0.0318, -0.0277,  0.5782,  ...,  0.7000, -1.2813,  0.0404],\n",
      "          [-1.1054, -1.9300,  0.9404,  ...,  0.3076,  0.4758,  0.4056]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.0895, -0.4960,  0.7020,  ...,  1.0467, -1.4085,  0.2152],\n",
      "          [ 0.0791, -0.5381,  0.6762,  ...,  0.9704, -1.4608,  0.1688],\n",
      "          [ 0.1027, -0.5037,  0.6422,  ...,  0.9563, -1.4311,  0.1368],\n",
      "          ...,\n",
      "          [ 0.1662, -0.4837,  0.6996,  ...,  0.9993, -1.4032,  0.1283],\n",
      "          [ 0.0504, -0.5189,  0.6468,  ...,  0.9972, -1.4196,  0.1924],\n",
      "          [ 0.1569, -0.4826,  0.6617,  ...,  0.9840, -1.4089,  0.1333]],\n",
      "\n",
      "         [[-1.3351, -0.4014,  1.0283,  ...,  0.6688, -0.3841,  0.3682],\n",
      "          [-1.3333, -0.4245,  0.9709,  ...,  0.6854, -0.3177,  0.3576],\n",
      "          [-1.3248, -0.4139,  0.8987,  ...,  0.7100, -0.2947,  0.3572],\n",
      "          ...,\n",
      "          [-1.3748, -0.3733,  0.9940,  ...,  0.6806, -0.3240,  0.3547],\n",
      "          [-1.3608, -0.4106,  0.9952,  ...,  0.6592, -0.3133,  0.3415],\n",
      "          [-1.3544, -0.3470,  0.9466,  ...,  0.6722, -0.3129,  0.3593]]],\n",
      "\n",
      "\n",
      "        [[[-0.1950,  0.1313,  0.2516,  ...,  1.1532, -0.9737,  0.1760],\n",
      "          [-0.1191, -0.0410,  0.3857,  ...,  0.8478, -1.0937,  0.0310],\n",
      "          [-0.0932, -0.0257,  0.3535,  ...,  0.7779, -1.0427, -0.0335],\n",
      "          ...,\n",
      "          [-0.1288,  0.0272,  0.3288,  ...,  0.9865, -1.0126,  0.0182],\n",
      "          [-0.0979,  0.0608,  0.2989,  ...,  0.9302, -1.0380,  0.0806],\n",
      "          [-0.0681,  0.0147,  0.3776,  ...,  0.8548, -1.0478,  0.0074]],\n",
      "\n",
      "         [[-1.7477, -0.5921,  0.5385,  ...,  0.7339,  0.4892,  0.2234],\n",
      "          [-1.7773, -0.6422,  0.5035,  ...,  0.7067,  0.5263,  0.1946],\n",
      "          [-1.8033, -0.6670,  0.4916,  ...,  0.6236,  0.6114,  0.1580],\n",
      "          ...,\n",
      "          [-1.7973, -0.6011,  0.5191,  ...,  0.6658,  0.6094,  0.1571],\n",
      "          [-1.8052, -0.6507,  0.5579,  ...,  0.6790,  0.4759,  0.2009],\n",
      "          [-1.8160, -0.5999,  0.5461,  ...,  0.6553,  0.4895,  0.2032]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.0895, -0.4960,  0.7020,  ...,  1.0467, -1.4085,  0.2152],\n",
      "          [-1.3351, -0.4014,  1.0283,  ...,  0.6688, -0.3841,  0.3682]],\n",
      "\n",
      "         [[ 0.0791, -0.5381,  0.6762,  ...,  0.9704, -1.4608,  0.1688],\n",
      "          [-1.3333, -0.4245,  0.9709,  ...,  0.6854, -0.3177,  0.3576]],\n",
      "\n",
      "         [[ 0.1027, -0.5037,  0.6422,  ...,  0.9563, -1.4311,  0.1368],\n",
      "          [-1.3248, -0.4139,  0.8987,  ...,  0.7100, -0.2947,  0.3572]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1662, -0.4837,  0.6996,  ...,  0.9993, -1.4032,  0.1283],\n",
      "          [-1.3748, -0.3733,  0.9940,  ...,  0.6806, -0.3240,  0.3547]],\n",
      "\n",
      "         [[ 0.0504, -0.5189,  0.6468,  ...,  0.9972, -1.4196,  0.1924],\n",
      "          [-1.3608, -0.4106,  0.9952,  ...,  0.6592, -0.3133,  0.3415]],\n",
      "\n",
      "         [[ 0.1569, -0.4826,  0.6617,  ...,  0.9840, -1.4089,  0.1333],\n",
      "          [-1.3544, -0.3470,  0.9466,  ...,  0.6722, -0.3129,  0.3593]]],\n",
      "\n",
      "\n",
      "        [[[-0.1950,  0.1313,  0.2516,  ...,  1.1532, -0.9737,  0.1760],\n",
      "          [-1.7477, -0.5921,  0.5385,  ...,  0.7339,  0.4892,  0.2234]],\n",
      "\n",
      "         [[-0.1191, -0.0410,  0.3857,  ...,  0.8478, -1.0937,  0.0310],\n",
      "          [-1.7773, -0.6422,  0.5035,  ...,  0.7067,  0.5263,  0.1946]],\n",
      "\n",
      "         [[-0.0932, -0.0257,  0.3535,  ...,  0.7779, -1.0427, -0.0335],\n",
      "          [-1.8033, -0.6670,  0.4916,  ...,  0.6236,  0.6114,  0.1580]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1288,  0.0272,  0.3288,  ...,  0.9865, -1.0126,  0.0182],\n",
      "          [-1.7973, -0.6011,  0.5191,  ...,  0.6658,  0.6094,  0.1571]],\n",
      "\n",
      "         [[-0.0979,  0.0608,  0.2989,  ...,  0.9302, -1.0380,  0.0806],\n",
      "          [-1.8052, -0.6507,  0.5579,  ...,  0.6790,  0.4759,  0.2009]],\n",
      "\n",
      "         [[-0.0681,  0.0147,  0.3776,  ...,  0.8548, -1.0478,  0.0074],\n",
      "          [-1.8160, -0.5999,  0.5461,  ...,  0.6553,  0.4895,  0.2032]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the MaseGraph for the compressed checkpoint to be used in future tutorials for hardware generation and distributed deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
