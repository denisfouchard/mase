{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "checkpoint = \"DeepWokLab/bert-tiny\"\n",
    "tokenizer_checkpoint = \"DeepWokLab/bert-tiny\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for DeepWokLab/bert-tiny.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads, inspired by the [NAS-BERT paper](https://arxiv.org/abs/2105.14444)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\": [\n",
    "        nn.Linear,\n",
    "        Identity,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_int` and `trial.suggest_categorical` functions to trigger the chosen sampler to choose parameter choices and layer types. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "    print(config)\n",
    "\n",
    "    # Update the paramaters in the config\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\",\n",
    "    ]:\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        print(f\"Chosen idx {chosen_idx} for param {param} ({len(search_space[param])})\")\n",
    "        setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "            print(\"DEBUG : \", new_layer_cls)\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-28 15:56:07,316] A new study created in memory with name: bert-tiny-nas-study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"DeepWokLab/bert-tiny\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.48.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Chosen idx 1 for param num_layers (3)\n",
      "Chosen idx 3 for param num_heads (4)\n",
      "Chosen idx 2 for param hidden_size (5)\n",
      "Chosen idx 3 for param intermediate_size (5)\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'torch.nn.modules.linear.Linear'>\n",
      "DEBUG :  <class 'chop.nn.modules.identity.Identity'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/home/infres/dfouchard-21/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 107/3125 00:04 < 02:06, 23.83 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-28 15:56:13,202] Trial 0 failed with parameters: {'num_layers': 1, 'num_heads': 3, 'hidden_size': 2, 'intermediate_size': 3, 'bert.encoder.layer.0.attention.self.query_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.value_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.pooler.dense_type': <class 'chop.nn.modules.identity.Identity'>} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3940603/1584329485.py\", line 16, in objective\n",
      "    trainer.train()\n",
      "  File \"/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/transformers/trainer.py\", line 2171, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/infres/dfouchard-21/miniconda3/envs/mase/lib/python3.12/site-packages/transformers/trainer.py\", line 2536, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-28 15:56:13,203] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      4\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-tiny-nas-study\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m construct_model(trial)\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m get_trainer(\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     10\u001b[0m     tokenized_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set the model as an attribute so we can fetch it later\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.12/site-packages/transformers/trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the model associated with the best trial as follows, and export to be used in future tutorials. In Tutorial 6, we'll see how to run mixed-precision quantization search on top of the model we've just found through NAS to further find the optimal quantization mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(f\"{Path.home()}/tutorial_5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Optimized Model with CompressionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the CompressionPipeline in Mase to run uniform quantization and pruning over the searched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for DeepWokLab/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[-3.0780,  0.5924, -0.1787,  ..., -0.0586,  0.8150,  0.4544],\n",
      "         [-1.0411, -1.0607, -0.1983,  ..., -0.4444, -0.6395,  0.2169],\n",
      "         [-1.6130,  0.0383, -0.1277,  ...,  0.5087, -0.6667,  1.1361],\n",
      "         ...,\n",
      "         [-2.1690, -1.6325,  1.3719,  ..., -0.4480, -1.6932,  2.0700],\n",
      "         [-1.4452, -0.9829,  1.1845,  ..., -0.8715, -0.6782,  2.6776],\n",
      "         [-0.3751, -1.1222, -0.4730,  ..., -0.1123,  0.5777,  2.1722]],\n",
      "\n",
      "        [[-3.0780,  0.5924, -0.1787,  ..., -0.0586,  0.8150,  0.4544],\n",
      "         [-2.2528, -1.1118, -1.2364,  ...,  0.8497,  0.0266,  1.5979],\n",
      "         [-1.4021,  0.1288, -0.2536,  ...,  0.4817, -0.0878,  0.1317],\n",
      "         ...,\n",
      "         [-1.9767, -0.4623,  1.2828,  ..., -1.1110, -1.4370,  0.9403],\n",
      "         [-0.6257, -1.1948,  0.3655,  ..., -0.5825, -0.7944,  2.7787],\n",
      "         [-0.3751, -1.1222, -0.4730,  ..., -0.1123,  0.5777,  2.1722]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ..., -8.2694e-01,\n",
      "          -1.0230e+00, -9.3578e-01],\n",
      "         [-8.8066e-02,  9.8811e-01,  2.4461e-01,  ...,  4.9001e-02,\n",
      "          -3.4140e-01, -8.5081e-01],\n",
      "         [-2.7581e-01,  4.1809e-01, -9.1334e-02,  ...,  1.8976e-01,\n",
      "          -5.7176e-01, -1.1565e+00],\n",
      "         ...,\n",
      "         [-5.8632e-01,  1.3269e-01,  3.7306e-01,  ..., -4.5581e-01,\n",
      "          -1.2439e-01, -1.3318e+00],\n",
      "         [ 6.4539e-02,  3.6997e-01, -8.2737e-02,  ..., -4.8478e-01,\n",
      "          -3.5593e-01, -4.7957e-01],\n",
      "         [-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  6.2710e-01,\n",
      "           4.9394e-02, -2.1723e-01]],\n",
      "\n",
      "        [[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ..., -8.2694e-01,\n",
      "          -1.0230e+00, -9.3578e-01],\n",
      "         [-3.4443e-01,  8.9774e-01,  1.1110e-03,  ..., -4.2412e-01,\n",
      "          -6.6626e-01, -1.2087e+00],\n",
      "         [-2.9832e-01,  1.5070e-01,  4.0540e-02,  ..., -1.7255e-01,\n",
      "          -1.6530e-01, -9.4831e-01],\n",
      "         ...,\n",
      "         [-5.9501e-02,  1.4082e-01,  6.7797e-01,  ..., -1.0184e-01,\n",
      "          -6.9826e-01, -8.7629e-01],\n",
      "         [-1.9077e-01,  4.4052e-01,  6.5247e-02,  ..., -2.6166e-01,\n",
      "          -4.5678e-02, -1.9659e-01],\n",
      "         [-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  6.2710e-01,\n",
      "           4.9394e-02, -2.1723e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ..., -8.2694e-01,\n",
      "          -1.0230e+00, -9.3578e-01],\n",
      "         [-8.8066e-02,  9.8811e-01,  2.4461e-01,  ...,  4.9001e-02,\n",
      "          -3.4140e-01, -8.5081e-01],\n",
      "         [-2.7581e-01,  4.1809e-01, -9.1334e-02,  ...,  1.8976e-01,\n",
      "          -5.7176e-01, -1.1565e+00],\n",
      "         ...,\n",
      "         [-5.8632e-01,  1.3269e-01,  3.7306e-01,  ..., -4.5581e-01,\n",
      "          -1.2439e-01, -1.3318e+00],\n",
      "         [ 6.4539e-02,  3.6997e-01, -8.2737e-02,  ..., -4.8478e-01,\n",
      "          -3.5593e-01, -4.7957e-01],\n",
      "         [-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  6.2710e-01,\n",
      "           4.9394e-02, -2.1723e-01]],\n",
      "\n",
      "        [[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ..., -8.2694e-01,\n",
      "          -1.0230e+00, -9.3578e-01],\n",
      "         [-3.4443e-01,  8.9774e-01,  1.1110e-03,  ..., -4.2412e-01,\n",
      "          -6.6626e-01, -1.2087e+00],\n",
      "         [-2.9832e-01,  1.5070e-01,  4.0540e-02,  ..., -1.7255e-01,\n",
      "          -1.6530e-01, -9.4831e-01],\n",
      "         ...,\n",
      "         [-5.9501e-02,  1.4082e-01,  6.7797e-01,  ..., -1.0184e-01,\n",
      "          -6.9826e-01, -8.7629e-01],\n",
      "         [-1.9077e-01,  4.4052e-01,  6.5247e-02,  ..., -2.6166e-01,\n",
      "          -4.5678e-02, -1.9659e-01],\n",
      "         [-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  6.2710e-01,\n",
      "           4.9394e-02, -2.1723e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ...,  8.2826e-01,\n",
      "           -3.2390e-01,  7.0866e-01],\n",
      "          [-2.5389e-01,  5.0420e-01, -7.3131e-01,  ..., -8.2694e-01,\n",
      "           -1.0230e+00, -9.3578e-01]],\n",
      "\n",
      "         [[-8.8066e-02,  9.8811e-01,  2.4461e-01,  ...,  6.6950e-02,\n",
      "            4.3259e-01,  8.0530e-01],\n",
      "          [ 3.8799e-01,  3.3920e-01, -2.1112e-01,  ...,  4.9001e-02,\n",
      "           -3.4140e-01, -8.5081e-01]],\n",
      "\n",
      "         [[-2.7581e-01,  4.1809e-01, -9.1334e-02,  ...,  9.7693e-02,\n",
      "            7.1801e-01,  8.0349e-01],\n",
      "          [-2.1532e-01,  1.2210e-01, -4.0217e-01,  ...,  1.8976e-01,\n",
      "           -5.7176e-01, -1.1565e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8632e-01,  1.3269e-01,  3.7306e-01,  ...,  4.9725e-01,\n",
      "            6.6014e-01,  9.9044e-01],\n",
      "          [-7.6854e-01, -9.5472e-02, -1.5891e-01,  ..., -4.5581e-01,\n",
      "           -1.2439e-01, -1.3318e+00]],\n",
      "\n",
      "         [[ 6.4539e-02,  3.6997e-01, -8.2737e-02,  ..., -3.0996e-01,\n",
      "            5.3244e-01,  3.3170e-02],\n",
      "          [-5.8279e-02, -1.2201e-02, -4.4949e-01,  ..., -4.8478e-01,\n",
      "           -3.5593e-01, -4.7957e-01]],\n",
      "\n",
      "         [[-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  1.6829e-01,\n",
      "            1.9102e-01,  1.5799e-01],\n",
      "          [-6.5272e-02, -4.7618e-01, -3.4037e-01,  ...,  6.2710e-01,\n",
      "            4.9394e-02, -2.1723e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4021e-01, -3.8003e-01, -5.0422e-01,  ...,  8.2826e-01,\n",
      "           -3.2390e-01,  7.0866e-01],\n",
      "          [-2.5389e-01,  5.0420e-01, -7.3131e-01,  ..., -8.2694e-01,\n",
      "           -1.0230e+00, -9.3578e-01]],\n",
      "\n",
      "         [[-3.4443e-01,  8.9774e-01,  1.1110e-03,  ...,  4.9691e-01,\n",
      "           -8.1089e-02,  3.5063e-01],\n",
      "          [ 4.5178e-01,  2.9113e-01, -2.2566e-01,  ..., -4.2412e-01,\n",
      "           -6.6626e-01, -1.2087e+00]],\n",
      "\n",
      "         [[-2.9832e-01,  1.5070e-01,  4.0540e-02,  ...,  5.4317e-01,\n",
      "            5.6942e-01,  1.0108e+00],\n",
      "          [-5.4296e-01,  3.2836e-01, -3.8412e-01,  ..., -1.7255e-01,\n",
      "           -1.6530e-01, -9.4831e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9501e-02,  1.4082e-01,  6.7797e-01,  ...,  8.0254e-01,\n",
      "            7.0040e-01,  6.9492e-01],\n",
      "          [-4.0564e-01,  3.3372e-01, -7.3073e-01,  ..., -1.0184e-01,\n",
      "           -6.9826e-01, -8.7629e-01]],\n",
      "\n",
      "         [[-1.9077e-01,  4.4052e-01,  6.5247e-02,  ...,  3.8379e-02,\n",
      "            3.3615e-01,  4.2539e-01],\n",
      "          [ 2.2021e-02, -1.4787e-01, -1.1574e-01,  ..., -2.6166e-01,\n",
      "           -4.5678e-02, -1.9659e-01]],\n",
      "\n",
      "         [[-3.2856e-01,  7.4179e-01,  3.9501e-01,  ...,  1.6829e-01,\n",
      "            1.9102e-01,  1.5799e-01],\n",
      "          [-6.5272e-02, -4.7618e-01, -3.4037e-01,  ...,  6.2710e-01,\n",
      "            4.9394e-02, -2.1723e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1216, -0.0896,  0.2856,  ...,  0.0346, -0.1351, -0.4705],\n",
      "         [ 0.1754, -0.1795, -0.0662,  ..., -0.3286,  0.2954,  0.5406],\n",
      "         [ 0.4378,  0.7988,  0.1939,  ...,  0.0811,  0.1294, -0.2249],\n",
      "         ...,\n",
      "         [-0.1076,  0.6002, -0.5255,  ...,  0.3371,  0.8197,  0.0570],\n",
      "         [-0.5622,  0.0065,  0.1854,  ..., -0.3578,  0.0453, -0.1193],\n",
      "         [-0.2726,  0.8204, -0.3765,  ...,  0.0626,  0.8577,  0.5000]],\n",
      "\n",
      "        [[-0.1216, -0.0896,  0.2856,  ...,  0.0346, -0.1351, -0.4705],\n",
      "         [ 0.0140, -0.2075,  0.2255,  ..., -0.0671,  0.4433,  1.0475],\n",
      "         [ 0.3668,  0.5535,  0.1240,  ...,  0.1951,  0.1416,  0.8472],\n",
      "         ...,\n",
      "         [-0.1273,  0.7310, -0.4145,  ...,  0.3894,  0.2018,  0.2462],\n",
      "         [-0.3664, -0.4024, -0.0406,  ..., -0.0786,  0.2639,  0.2568],\n",
      "         [-0.2726,  0.8204, -0.3765,  ...,  0.0626,  0.8577,  0.5000]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1216, -0.0896,  0.2856,  ...,  0.0346, -0.1351, -0.4705],\n",
      "         [ 0.1754, -0.1795, -0.0662,  ..., -0.3286,  0.2954,  0.5406],\n",
      "         [ 0.4378,  0.7988,  0.1939,  ...,  0.0811,  0.1294, -0.2249],\n",
      "         ...,\n",
      "         [-0.1076,  0.6002, -0.5255,  ...,  0.3371,  0.8197,  0.0570],\n",
      "         [-0.5622,  0.0065,  0.1854,  ..., -0.3578,  0.0453, -0.1193],\n",
      "         [-0.2726,  0.8204, -0.3765,  ...,  0.0626,  0.8577,  0.5000]],\n",
      "\n",
      "        [[-0.1216, -0.0896,  0.2856,  ...,  0.0346, -0.1351, -0.4705],\n",
      "         [ 0.0140, -0.2075,  0.2255,  ..., -0.0671,  0.4433,  1.0475],\n",
      "         [ 0.3668,  0.5535,  0.1240,  ...,  0.1951,  0.1416,  0.8472],\n",
      "         ...,\n",
      "         [-0.1273,  0.7310, -0.4145,  ...,  0.3894,  0.2018,  0.2462],\n",
      "         [-0.3664, -0.4024, -0.0406,  ..., -0.0786,  0.2639,  0.2568],\n",
      "         [-0.2726,  0.8204, -0.3765,  ...,  0.0626,  0.8577,  0.5000]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1216, -0.0896,  0.2856,  ..., -0.5561,  0.5813, -0.2736],\n",
      "          [ 0.5347, -0.5976, -0.1350,  ...,  0.0346, -0.1351, -0.4705]],\n",
      "\n",
      "         [[ 0.1754, -0.1795, -0.0662,  ..., -0.3779, -0.1404, -0.1811],\n",
      "          [ 0.2325, -0.0189,  0.3269,  ..., -0.3286,  0.2954,  0.5406]],\n",
      "\n",
      "         [[ 0.4378,  0.7988,  0.1939,  ..., -0.1481,  0.0389,  0.0986],\n",
      "          [ 0.3201,  0.2929, -0.0748,  ...,  0.0811,  0.1294, -0.2249]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1076,  0.6002, -0.5255,  ..., -0.8965, -0.5490,  0.0615],\n",
      "          [ 0.2412,  0.7823,  0.3823,  ...,  0.3371,  0.8197,  0.0570]],\n",
      "\n",
      "         [[-0.5622,  0.0065,  0.1854,  ..., -0.2184, -0.3575, -0.4785],\n",
      "          [-0.1121, -0.0729, -0.2419,  ..., -0.3578,  0.0453, -0.1193]],\n",
      "\n",
      "         [[-0.2726,  0.8204, -0.3765,  ..., -0.1540,  0.1509, -0.2488],\n",
      "          [ 0.9432, -0.1517,  0.2364,  ...,  0.0626,  0.8577,  0.5000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1216, -0.0896,  0.2856,  ..., -0.5561,  0.5813, -0.2736],\n",
      "          [ 0.5347, -0.5976, -0.1350,  ...,  0.0346, -0.1351, -0.4705]],\n",
      "\n",
      "         [[ 0.0140, -0.2075,  0.2255,  ..., -0.4402, -0.3673,  0.0615],\n",
      "          [ 0.4590,  0.1596,  0.0421,  ..., -0.0671,  0.4433,  1.0475]],\n",
      "\n",
      "         [[ 0.3668,  0.5535,  0.1240,  ..., -0.2702, -0.1019, -0.1994],\n",
      "          [ 0.2697, -0.1085, -0.0285,  ...,  0.1951,  0.1416,  0.8472]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1273,  0.7310, -0.4145,  ..., -0.7074, -0.3236,  0.2615],\n",
      "          [ 0.3473,  0.8310,  0.3119,  ...,  0.3894,  0.2018,  0.2462]],\n",
      "\n",
      "         [[-0.3664, -0.4024, -0.0406,  ..., -0.1981, -0.2290, -0.1980],\n",
      "          [ 0.3067, -0.0806,  0.1283,  ..., -0.0786,  0.2639,  0.2568]],\n",
      "\n",
      "         [[-0.2726,  0.8204, -0.3765,  ..., -0.1540,  0.1509, -0.2488],\n",
      "          [ 0.9432, -0.1517,  0.2364,  ...,  0.0626,  0.8577,  0.5000]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.6305,  0.5582,  0.2390,  ..., -0.4929,  0.0454, -0.4412],\n",
      "         [ 0.2621,  0.2700,  0.3122,  ...,  0.0162, -0.7389, -0.1548],\n",
      "         [ 0.1676, -0.5336, -0.3364,  ..., -0.0461,  0.3465, -0.5028],\n",
      "         ...,\n",
      "         [ 0.2678, -0.3002, -0.0183,  ..., -0.2274,  0.1872,  0.0178],\n",
      "         [ 0.1707, -0.5136,  0.4704,  ..., -0.4203,  0.3273, -0.1332],\n",
      "         [-0.1394, -0.4062,  0.5720,  ..., -0.0295,  0.4792,  0.0578]],\n",
      "\n",
      "        [[ 0.6305,  0.5582,  0.2390,  ..., -0.4929,  0.0454, -0.4412],\n",
      "         [ 0.0965,  0.8224,  0.3404,  ...,  0.1783, -0.6280, -0.2610],\n",
      "         [ 0.2467, -0.4596, -0.8713,  ..., -0.1598,  0.1323, -0.8119],\n",
      "         ...,\n",
      "         [ 0.2607, -0.6580,  0.2494,  ..., -0.0246,  0.6092, -0.4392],\n",
      "         [ 0.6906, -0.4311,  0.1650,  ..., -0.0626, -0.2553, -0.1339],\n",
      "         [-0.1394, -0.4062,  0.5720,  ..., -0.0295,  0.4792,  0.0578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.6305,  0.5582,  0.2390,  ..., -0.4929,  0.0454, -0.4412],\n",
      "         [ 0.2621,  0.2700,  0.3122,  ...,  0.0162, -0.7389, -0.1548],\n",
      "         [ 0.1676, -0.5336, -0.3364,  ..., -0.0461,  0.3465, -0.5028],\n",
      "         ...,\n",
      "         [ 0.2678, -0.3002, -0.0183,  ..., -0.2274,  0.1872,  0.0178],\n",
      "         [ 0.1707, -0.5136,  0.4704,  ..., -0.4203,  0.3273, -0.1332],\n",
      "         [-0.1394, -0.4062,  0.5720,  ..., -0.0295,  0.4792,  0.0578]],\n",
      "\n",
      "        [[ 0.6305,  0.5582,  0.2390,  ..., -0.4929,  0.0454, -0.4412],\n",
      "         [ 0.0965,  0.8224,  0.3404,  ...,  0.1783, -0.6280, -0.2610],\n",
      "         [ 0.2467, -0.4596, -0.8713,  ..., -0.1598,  0.1323, -0.8119],\n",
      "         ...,\n",
      "         [ 0.2607, -0.6580,  0.2494,  ..., -0.0246,  0.6092, -0.4392],\n",
      "         [ 0.6906, -0.4311,  0.1650,  ..., -0.0626, -0.2553, -0.1339],\n",
      "         [-0.1394, -0.4062,  0.5720,  ..., -0.0295,  0.4792,  0.0578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.6305,  0.5582,  0.2390,  ...,  0.1806, -0.4104,  0.5536],\n",
      "          [ 0.7373,  0.2680, -0.4119,  ..., -0.4929,  0.0454, -0.4412]],\n",
      "\n",
      "         [[ 0.2621,  0.2700,  0.3122,  ..., -0.6241, -0.7953,  0.3342],\n",
      "          [ 0.5364,  0.6761,  0.1579,  ...,  0.0162, -0.7389, -0.1548]],\n",
      "\n",
      "         [[ 0.1676, -0.5336, -0.3364,  ...,  0.3089,  0.4650, -0.0175],\n",
      "          [ 0.0468,  0.3573,  0.0613,  ..., -0.0461,  0.3465, -0.5028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2678, -0.3002, -0.0183,  ...,  0.1731, -0.0547,  0.4120],\n",
      "          [-0.2676, -0.1991,  0.2017,  ..., -0.2274,  0.1872,  0.0178]],\n",
      "\n",
      "         [[ 0.1707, -0.5136,  0.4704,  ...,  0.1517,  0.1716,  0.1438],\n",
      "          [ 0.6444,  0.0789,  0.2949,  ..., -0.4203,  0.3273, -0.1332]],\n",
      "\n",
      "         [[-0.1394, -0.4062,  0.5720,  ...,  0.2943, -0.1144,  0.4924],\n",
      "          [ 0.3573, -0.3157, -0.1683,  ..., -0.0295,  0.4792,  0.0578]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6305,  0.5582,  0.2390,  ...,  0.1806, -0.4104,  0.5536],\n",
      "          [ 0.7373,  0.2680, -0.4119,  ..., -0.4929,  0.0454, -0.4412]],\n",
      "\n",
      "         [[ 0.0965,  0.8224,  0.3404,  ..., -1.0516, -0.9078,  0.9355],\n",
      "          [ 0.9480,  0.2482, -0.3007,  ...,  0.1783, -0.6280, -0.2610]],\n",
      "\n",
      "         [[ 0.2467, -0.4596, -0.8713,  ...,  0.2132,  0.0664, -0.1538],\n",
      "          [-0.0193,  0.5460, -0.1196,  ..., -0.1598,  0.1323, -0.8119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2607, -0.6580,  0.2494,  ...,  0.0428,  0.2363,  0.5718],\n",
      "          [-0.1377,  0.0884,  0.3445,  ..., -0.0246,  0.6092, -0.4392]],\n",
      "\n",
      "         [[ 0.6906, -0.4311,  0.1650,  ..., -0.2326, -0.2403,  0.0384],\n",
      "          [ 0.8273, -0.0041,  0.1678,  ..., -0.0626, -0.2553, -0.1339]],\n",
      "\n",
      "         [[-0.1394, -0.4062,  0.5720,  ...,  0.2943, -0.1144,  0.4924],\n",
      "          [ 0.3573, -0.3157, -0.1683,  ..., -0.0295,  0.4792,  0.0578]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.4872, -0.1731,  0.2576,  ...,  0.1217,  0.0424,  0.0692],\n",
      "          [ 0.4603, -0.1957,  0.2183,  ...,  0.1202,  0.0764,  0.0724],\n",
      "          [ 0.4646, -0.2257,  0.1964,  ...,  0.1465,  0.0866,  0.0396],\n",
      "          ...,\n",
      "          [ 0.4765, -0.1883,  0.2179,  ...,  0.1267,  0.0727,  0.0544],\n",
      "          [ 0.4814, -0.1867,  0.2249,  ...,  0.1276,  0.0666,  0.0562],\n",
      "          [ 0.4794, -0.1913,  0.2260,  ...,  0.1368,  0.0701,  0.0609]],\n",
      "\n",
      "         [[ 0.2263,  0.0650,  0.0926,  ..., -0.0477,  0.0951, -0.2154],\n",
      "          [ 0.1942,  0.0281,  0.0566,  ..., -0.0199,  0.0561, -0.2233],\n",
      "          [ 0.1903,  0.0442,  0.0526,  ..., -0.0043,  0.0426, -0.2185],\n",
      "          ...,\n",
      "          [ 0.1738,  0.0210,  0.0647,  ...,  0.0019,  0.0607, -0.2175],\n",
      "          [ 0.2044,  0.0275,  0.0729,  ..., -0.0125,  0.0414, -0.2227],\n",
      "          [ 0.1626,  0.0435,  0.0624,  ..., -0.0219,  0.0839, -0.2253]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2256, -0.0427, -0.0362,  ...,  0.1031,  0.2008,  0.2373],\n",
      "          [ 0.2207, -0.0650, -0.0739,  ...,  0.0908,  0.2379,  0.2257],\n",
      "          [ 0.2061, -0.0936, -0.1287,  ...,  0.0842,  0.3296,  0.2058],\n",
      "          ...,\n",
      "          [ 0.2009, -0.0565, -0.0942,  ...,  0.0976,  0.3048,  0.2222],\n",
      "          [ 0.2095, -0.0487, -0.0725,  ...,  0.1014,  0.2479,  0.2334],\n",
      "          [ 0.2224, -0.0607, -0.0792,  ...,  0.0852,  0.2518,  0.2258]],\n",
      "\n",
      "         [[ 0.0133,  0.0014, -0.0198,  ..., -0.0938,  0.0517, -0.3110],\n",
      "          [ 0.0660,  0.0169, -0.0303,  ..., -0.0830,  0.0373, -0.2830],\n",
      "          [ 0.1300,  0.0562, -0.0408,  ..., -0.0808,  0.0216, -0.2998],\n",
      "          ...,\n",
      "          [ 0.0536,  0.0352, -0.0201,  ..., -0.0853,  0.0626, -0.3460],\n",
      "          [ 0.0758,  0.0410, -0.0244,  ..., -0.0724,  0.0378, -0.3065],\n",
      "          [ 0.0923,  0.0245, -0.0299,  ..., -0.0749,  0.0523, -0.3141]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.4872, -0.1731,  0.2576,  ...,  0.1217,  0.0424,  0.0692],\n",
      "          [ 0.2263,  0.0650,  0.0926,  ..., -0.0477,  0.0951, -0.2154]],\n",
      "\n",
      "         [[ 0.4603, -0.1957,  0.2183,  ...,  0.1202,  0.0764,  0.0724],\n",
      "          [ 0.1942,  0.0281,  0.0566,  ..., -0.0199,  0.0561, -0.2233]],\n",
      "\n",
      "         [[ 0.4646, -0.2257,  0.1964,  ...,  0.1465,  0.0866,  0.0396],\n",
      "          [ 0.1903,  0.0442,  0.0526,  ..., -0.0043,  0.0426, -0.2185]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4765, -0.1883,  0.2179,  ...,  0.1267,  0.0727,  0.0544],\n",
      "          [ 0.1738,  0.0210,  0.0647,  ...,  0.0019,  0.0607, -0.2175]],\n",
      "\n",
      "         [[ 0.4814, -0.1867,  0.2249,  ...,  0.1276,  0.0666,  0.0562],\n",
      "          [ 0.2044,  0.0275,  0.0729,  ..., -0.0125,  0.0414, -0.2227]],\n",
      "\n",
      "         [[ 0.4794, -0.1913,  0.2260,  ...,  0.1368,  0.0701,  0.0609],\n",
      "          [ 0.1626,  0.0435,  0.0624,  ..., -0.0219,  0.0839, -0.2253]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2256, -0.0427, -0.0362,  ...,  0.1031,  0.2008,  0.2373],\n",
      "          [ 0.0133,  0.0014, -0.0198,  ..., -0.0938,  0.0517, -0.3110]],\n",
      "\n",
      "         [[ 0.2207, -0.0650, -0.0739,  ...,  0.0908,  0.2379,  0.2257],\n",
      "          [ 0.0660,  0.0169, -0.0303,  ..., -0.0830,  0.0373, -0.2830]],\n",
      "\n",
      "         [[ 0.2061, -0.0936, -0.1287,  ...,  0.0842,  0.3296,  0.2058],\n",
      "          [ 0.1300,  0.0562, -0.0408,  ..., -0.0808,  0.0216, -0.2998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2009, -0.0565, -0.0942,  ...,  0.0976,  0.3048,  0.2222],\n",
      "          [ 0.0536,  0.0352, -0.0201,  ..., -0.0853,  0.0626, -0.3460]],\n",
      "\n",
      "         [[ 0.2095, -0.0487, -0.0725,  ...,  0.1014,  0.2479,  0.2334],\n",
      "          [ 0.0758,  0.0410, -0.0244,  ..., -0.0724,  0.0378, -0.3065]],\n",
      "\n",
      "         [[ 0.2224, -0.0607, -0.0792,  ...,  0.0852,  0.2518,  0.2258],\n",
      "          [ 0.0923,  0.0245, -0.0299,  ..., -0.0749,  0.0523, -0.3141]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-3.0497,  0.2664, -0.5972,  ..., -0.2594,  1.0425, -0.4525],\n",
      "         [-0.4284, -1.4437, -0.8029,  ..., -0.6532, -0.6275, -0.4643],\n",
      "         [-1.2716, -0.4326, -0.4445,  ...,  0.6117, -0.7935,  0.1712],\n",
      "         ...,\n",
      "         [-1.6602, -1.8974,  0.9409,  ..., -0.6217, -1.7680,  1.1430],\n",
      "         [-0.9064, -1.3184,  0.8974,  ..., -0.9085, -0.6362,  1.9980],\n",
      "         [ 0.2814, -1.3570, -0.6699,  ..., -0.3492,  0.7005,  1.2700]],\n",
      "\n",
      "        [[-2.9859,  0.2882, -0.5015,  ..., -0.1361,  1.0117, -0.4021],\n",
      "         [-1.9302, -1.3739, -1.8281,  ...,  0.9786,  0.2250,  0.7824],\n",
      "         [-0.8782, -0.2971, -0.6044,  ...,  0.4339, -0.1967, -0.8138],\n",
      "         ...,\n",
      "         [-1.4045, -0.6685,  1.0013,  ..., -1.1963, -1.7240,  0.2885],\n",
      "         [ 0.0644, -1.6060,  0.2585,  ..., -0.5375, -0.7979,  2.1810],\n",
      "         [ 0.3431, -1.3861, -0.6317,  ..., -0.2887,  0.6609,  1.3682]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.4328, -1.8710,  0.4139,  ...,  0.0068,  0.1196,  1.5732],\n",
      "         [-0.1734,  1.0332,  0.2869,  ..., -0.6822,  0.6949, -0.0598],\n",
      "         [-0.0190,  0.3088,  0.2741,  ..., -0.6251, -0.4978, -0.4849],\n",
      "         ...,\n",
      "         [ 0.2584,  0.5738,  0.5814,  ..., -0.2348,  0.2634, -0.4174],\n",
      "         [-0.2877, -0.1660,  0.6788,  ..., -0.1270,  0.3522,  0.3393],\n",
      "         [-0.0936,  0.1965, -0.1020,  ..., -0.1023, -0.1306,  0.1347]],\n",
      "\n",
      "        [[-0.4155, -1.9226,  0.3595,  ...,  0.0096,  0.1445,  1.6018],\n",
      "         [-0.1191, -0.2060, -0.4535,  ..., -0.7121,  0.4788,  0.6467],\n",
      "         [-0.2875,  0.1201,  0.8360,  ..., -0.1790, -0.1000,  0.0746],\n",
      "         ...,\n",
      "         [ 0.0157,  0.0275,  0.3417,  ..., -0.1847,  0.3478, -0.2465],\n",
      "         [ 0.2490,  0.0375,  0.3048,  ...,  0.3807, -0.0300,  0.6218],\n",
      "         [-0.0908,  0.1460, -0.1269,  ..., -0.1176, -0.1029,  0.1574]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.4328, -1.8710,  0.4139,  ...,  0.0068,  0.1196,  1.5732],\n",
      "         [-0.1734,  1.0332,  0.2869,  ..., -0.6822,  0.6949, -0.0598],\n",
      "         [-0.0190,  0.3088,  0.2741,  ..., -0.6251, -0.4978, -0.4849],\n",
      "         ...,\n",
      "         [ 0.2584,  0.5738,  0.5814,  ..., -0.2348,  0.2634, -0.4174],\n",
      "         [-0.2877, -0.1660,  0.6788,  ..., -0.1270,  0.3522,  0.3393],\n",
      "         [-0.0936,  0.1965, -0.1020,  ..., -0.1023, -0.1306,  0.1347]],\n",
      "\n",
      "        [[-0.4155, -1.9226,  0.3595,  ...,  0.0096,  0.1445,  1.6018],\n",
      "         [-0.1191, -0.2060, -0.4535,  ..., -0.7121,  0.4788,  0.6467],\n",
      "         [-0.2875,  0.1201,  0.8360,  ..., -0.1790, -0.1000,  0.0746],\n",
      "         ...,\n",
      "         [ 0.0157,  0.0275,  0.3417,  ..., -0.1847,  0.3478, -0.2465],\n",
      "         [ 0.2490,  0.0375,  0.3048,  ...,  0.3807, -0.0300,  0.6218],\n",
      "         [-0.0908,  0.1460, -0.1269,  ..., -0.1176, -0.1029,  0.1574]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.4328, -1.8710,  0.4139,  ...,  1.8855,  0.0136, -1.8668],\n",
      "          [-0.7063,  0.3994, -0.8868,  ...,  0.0068,  0.1196,  1.5732]],\n",
      "\n",
      "         [[-0.1734,  1.0332,  0.2869,  ..., -0.0934, -0.0803, -0.1312],\n",
      "          [ 0.1011, -0.1443,  0.4446,  ..., -0.6822,  0.6949, -0.0598]],\n",
      "\n",
      "         [[-0.0190,  0.3088,  0.2741,  ...,  0.6336,  0.1022, -0.6813],\n",
      "          [ 0.2745, -0.6246,  0.6001,  ..., -0.6251, -0.4978, -0.4849]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2584,  0.5738,  0.5814,  ...,  0.2931, -0.0726,  0.2689],\n",
      "          [ 0.5743, -0.1899, -0.3336,  ..., -0.2348,  0.2634, -0.4174]],\n",
      "\n",
      "         [[-0.2877, -0.1660,  0.6788,  ...,  0.0961,  0.1397, -0.4761],\n",
      "          [ 0.8465, -0.0532,  0.6755,  ..., -0.1270,  0.3522,  0.3393]],\n",
      "\n",
      "         [[-0.0936,  0.1965, -0.1020,  ...,  0.0716,  0.1412,  0.1068],\n",
      "          [ 0.4098, -0.2494,  0.9518,  ..., -0.1023, -0.1306,  0.1347]]],\n",
      "\n",
      "\n",
      "        [[[-0.4155, -1.9226,  0.3595,  ...,  1.7975,  0.0285, -1.8805],\n",
      "          [-0.7471,  0.4020, -0.8921,  ...,  0.0096,  0.1445,  1.6018]],\n",
      "\n",
      "         [[-0.1191, -0.2060, -0.4535,  ..., -0.0693, -0.6537, -0.5275],\n",
      "          [-0.3675,  0.1191,  0.4259,  ..., -0.7121,  0.4788,  0.6467]],\n",
      "\n",
      "         [[-0.2875,  0.1201,  0.8360,  ...,  0.8692,  0.3125, -0.4054],\n",
      "          [ 0.4723, -0.5110, -0.1233,  ..., -0.1790, -0.1000,  0.0746]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0157,  0.0275,  0.3417,  ...,  0.0591,  0.0766,  0.1562],\n",
      "          [ 0.3266, -0.3696,  0.1265,  ..., -0.1847,  0.3478, -0.2465]],\n",
      "\n",
      "         [[ 0.2490,  0.0375,  0.3048,  ..., -0.0451,  0.1832, -0.7834],\n",
      "          [ 0.3227, -0.2310,  0.0079,  ...,  0.3807, -0.0300,  0.6218]],\n",
      "\n",
      "         [[-0.0908,  0.1460, -0.1269,  ...,  0.0049,  0.1546,  0.1019],\n",
      "          [ 0.4024, -0.2439,  0.9557,  ..., -0.1176, -0.1029,  0.1574]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-3.0497,  0.2664, -0.5972,  ..., -0.2594,  1.0425, -0.4525],\n",
      "         [-0.4284, -1.4437, -0.8029,  ..., -0.6532, -0.6275, -0.4643],\n",
      "         [-1.2716, -0.4326, -0.4445,  ...,  0.6117, -0.7935,  0.1712],\n",
      "         ...,\n",
      "         [-1.6602, -1.8974,  0.9409,  ..., -0.6217, -1.7680,  1.1430],\n",
      "         [-0.9064, -1.3184,  0.8974,  ..., -0.9085, -0.6362,  1.9980],\n",
      "         [ 0.2814, -1.3570, -0.6699,  ..., -0.3492,  0.7005,  1.2700]],\n",
      "\n",
      "        [[-2.9859,  0.2882, -0.5015,  ..., -0.1361,  1.0117, -0.4021],\n",
      "         [-1.9302, -1.3739, -1.8281,  ...,  0.9786,  0.2250,  0.7824],\n",
      "         [-0.8782, -0.2971, -0.6044,  ...,  0.4339, -0.1967, -0.8138],\n",
      "         ...,\n",
      "         [-1.4045, -0.6685,  1.0013,  ..., -1.1963, -1.7240,  0.2885],\n",
      "         [ 0.0644, -1.6060,  0.2585,  ..., -0.5375, -0.7979,  2.1810],\n",
      "         [ 0.3431, -1.3861, -0.6317,  ..., -0.2887,  0.6609,  1.3682]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-3.0497,  0.2664, -0.5972,  ..., -0.2594,  1.0425, -0.4525],\n",
      "         [-0.4284, -1.4437, -0.8029,  ..., -0.6532, -0.6275, -0.4643],\n",
      "         [-1.2716, -0.4326, -0.4445,  ...,  0.6117, -0.7935,  0.1712],\n",
      "         ...,\n",
      "         [-1.6602, -1.8974,  0.9409,  ..., -0.6217, -1.7680,  1.1430],\n",
      "         [-0.9064, -1.3184,  0.8974,  ..., -0.9085, -0.6362,  1.9980],\n",
      "         [ 0.2814, -1.3570, -0.6699,  ..., -0.3492,  0.7005,  1.2700]],\n",
      "\n",
      "        [[-2.9859,  0.2882, -0.5015,  ..., -0.1361,  1.0117, -0.4021],\n",
      "         [-1.9302, -1.3739, -1.8281,  ...,  0.9786,  0.2250,  0.7824],\n",
      "         [-0.8782, -0.2971, -0.6044,  ...,  0.4339, -0.1967, -0.8138],\n",
      "         ...,\n",
      "         [-1.4045, -0.6685,  1.0013,  ..., -1.1963, -1.7240,  0.2885],\n",
      "         [ 0.0644, -1.6060,  0.2585,  ..., -0.5375, -0.7979,  2.1810],\n",
      "         [ 0.3431, -1.3861, -0.6317,  ..., -0.2887,  0.6609,  1.3682]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-3.0497,  0.2664, -0.5972,  ..., -0.3150, -0.0318,  0.8695],\n",
      "          [-0.8818, -0.4680,  0.4594,  ..., -0.2594,  1.0425, -0.4525]],\n",
      "\n",
      "         [[-0.4284, -1.4437, -0.8029,  ..., -0.5524, -2.2332, -0.1506],\n",
      "          [-1.1575,  1.1463,  0.1727,  ..., -0.6532, -0.6275, -0.4643]],\n",
      "\n",
      "         [[-1.2716, -0.4326, -0.4445,  ..., -0.6342, -0.5977, -1.0302],\n",
      "          [-1.5621, -0.1947,  0.8246,  ...,  0.6117, -0.7935,  0.1712]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6602, -1.8974,  0.9409,  ...,  0.4446, -1.0252, -0.4460],\n",
      "          [ 1.1054,  2.2482,  0.4456,  ..., -0.6217, -1.7680,  1.1430]],\n",
      "\n",
      "         [[-0.9064, -1.3184,  0.8974,  ..., -0.4311,  0.2397, -1.3265],\n",
      "          [-1.3286, -0.8839, -1.6031,  ..., -0.9085, -0.6362,  1.9980]],\n",
      "\n",
      "         [[ 0.2814, -1.3570, -0.6699,  ..., -0.3794, -1.9004, -2.1871],\n",
      "          [ 0.8116, -0.1129, -1.0180,  ..., -0.3492,  0.7005,  1.2700]]],\n",
      "\n",
      "\n",
      "        [[[-2.9859,  0.2882, -0.5015,  ..., -0.2725,  0.1414,  0.7709],\n",
      "          [-0.9411, -0.4664,  0.5252,  ..., -0.1361,  1.0117, -0.4021]],\n",
      "\n",
      "         [[-1.9302, -1.3739, -1.8281,  ..., -0.4701, -0.5864,  0.6159],\n",
      "          [-2.7671,  0.4476,  0.9595,  ...,  0.9786,  0.2250,  0.7824]],\n",
      "\n",
      "         [[-0.8782, -0.2971, -0.6044,  ..., -2.1336, -1.1752, -0.1265],\n",
      "          [-1.2969, -0.3310,  0.7282,  ...,  0.4339, -0.1967, -0.8138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4045, -0.6685,  1.0013,  ..., -1.0380, -0.2678, -1.6008],\n",
      "          [ 1.6566,  0.0314,  1.6152,  ..., -1.1963, -1.7240,  0.2885]],\n",
      "\n",
      "         [[ 0.0644, -1.6060,  0.2585,  ..., -0.5135, -0.6642, -0.6016],\n",
      "          [-2.4496, -0.2179, -0.1673,  ..., -0.5375, -0.7979,  2.1810]],\n",
      "\n",
      "         [[ 0.3431, -1.3861, -0.6317,  ..., -0.3762, -1.7607, -2.2605],\n",
      "          [ 0.7767, -0.0540, -0.9969,  ..., -0.2887,  0.6609,  1.3682]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-3.0497,  0.2664, -0.5972,  ..., -0.2594,  1.0425, -0.4525],\n",
      "         [-0.4284, -1.4437, -0.8029,  ..., -0.6532, -0.6275, -0.4643],\n",
      "         [-1.2716, -0.4326, -0.4445,  ...,  0.6117, -0.7935,  0.1712],\n",
      "         ...,\n",
      "         [-1.6602, -1.8974,  0.9409,  ..., -0.6217, -1.7680,  1.1430],\n",
      "         [-0.9064, -1.3184,  0.8974,  ..., -0.9085, -0.6362,  1.9980],\n",
      "         [ 0.2814, -1.3570, -0.6699,  ..., -0.3492,  0.7005,  1.2700]],\n",
      "\n",
      "        [[-2.9859,  0.2882, -0.5015,  ..., -0.1361,  1.0117, -0.4021],\n",
      "         [-1.9302, -1.3739, -1.8281,  ...,  0.9786,  0.2250,  0.7824],\n",
      "         [-0.8782, -0.2971, -0.6044,  ...,  0.4339, -0.1967, -0.8138],\n",
      "         ...,\n",
      "         [-1.4045, -0.6685,  1.0013,  ..., -1.1963, -1.7240,  0.2885],\n",
      "         [ 0.0644, -1.6060,  0.2585,  ..., -0.5375, -0.7979,  2.1810],\n",
      "         [ 0.3431, -1.3861, -0.6317,  ..., -0.2887,  0.6609,  1.3682]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-3.0497,  0.2664, -0.5972,  ..., -0.2594,  1.0425, -0.4525],\n",
      "         [-0.4284, -1.4437, -0.8029,  ..., -0.6532, -0.6275, -0.4643],\n",
      "         [-1.2716, -0.4326, -0.4445,  ...,  0.6117, -0.7935,  0.1712],\n",
      "         ...,\n",
      "         [-1.6602, -1.8974,  0.9409,  ..., -0.6217, -1.7680,  1.1430],\n",
      "         [-0.9064, -1.3184,  0.8974,  ..., -0.9085, -0.6362,  1.9980],\n",
      "         [ 0.2814, -1.3570, -0.6699,  ..., -0.3492,  0.7005,  1.2700]],\n",
      "\n",
      "        [[-2.9859,  0.2882, -0.5015,  ..., -0.1361,  1.0117, -0.4021],\n",
      "         [-1.9302, -1.3739, -1.8281,  ...,  0.9786,  0.2250,  0.7824],\n",
      "         [-0.8782, -0.2971, -0.6044,  ...,  0.4339, -0.1967, -0.8138],\n",
      "         ...,\n",
      "         [-1.4045, -0.6685,  1.0013,  ..., -1.1963, -1.7240,  0.2885],\n",
      "         [ 0.0644, -1.6060,  0.2585,  ..., -0.5375, -0.7979,  2.1810],\n",
      "         [ 0.3431, -1.3861, -0.6317,  ..., -0.2887,  0.6609,  1.3682]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-3.0497,  0.2664, -0.5972,  ..., -0.3150, -0.0318,  0.8695],\n",
      "          [-0.8818, -0.4680,  0.4594,  ..., -0.2594,  1.0425, -0.4525]],\n",
      "\n",
      "         [[-0.4284, -1.4437, -0.8029,  ..., -0.5524, -2.2332, -0.1506],\n",
      "          [-1.1575,  1.1463,  0.1727,  ..., -0.6532, -0.6275, -0.4643]],\n",
      "\n",
      "         [[-1.2716, -0.4326, -0.4445,  ..., -0.6342, -0.5977, -1.0302],\n",
      "          [-1.5621, -0.1947,  0.8246,  ...,  0.6117, -0.7935,  0.1712]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6602, -1.8974,  0.9409,  ...,  0.4446, -1.0252, -0.4460],\n",
      "          [ 1.1054,  2.2482,  0.4456,  ..., -0.6217, -1.7680,  1.1430]],\n",
      "\n",
      "         [[-0.9064, -1.3184,  0.8974,  ..., -0.4311,  0.2397, -1.3265],\n",
      "          [-1.3286, -0.8839, -1.6031,  ..., -0.9085, -0.6362,  1.9980]],\n",
      "\n",
      "         [[ 0.2814, -1.3570, -0.6699,  ..., -0.3794, -1.9004, -2.1871],\n",
      "          [ 0.8116, -0.1129, -1.0180,  ..., -0.3492,  0.7005,  1.2700]]],\n",
      "\n",
      "\n",
      "        [[[-2.9859,  0.2882, -0.5015,  ..., -0.2725,  0.1414,  0.7709],\n",
      "          [-0.9411, -0.4664,  0.5252,  ..., -0.1361,  1.0117, -0.4021]],\n",
      "\n",
      "         [[-1.9302, -1.3739, -1.8281,  ..., -0.4701, -0.5864,  0.6159],\n",
      "          [-2.7671,  0.4476,  0.9595,  ...,  0.9786,  0.2250,  0.7824]],\n",
      "\n",
      "         [[-0.8782, -0.2971, -0.6044,  ..., -2.1336, -1.1752, -0.1265],\n",
      "          [-1.2969, -0.3310,  0.7282,  ...,  0.4339, -0.1967, -0.8138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4045, -0.6685,  1.0013,  ..., -1.0380, -0.2678, -1.6008],\n",
      "          [ 1.6566,  0.0314,  1.6152,  ..., -1.1963, -1.7240,  0.2885]],\n",
      "\n",
      "         [[ 0.0644, -1.6060,  0.2585,  ..., -0.5135, -0.6642, -0.6016],\n",
      "          [-2.4496, -0.2179, -0.1673,  ..., -0.5375, -0.7979,  2.1810]],\n",
      "\n",
      "         [[ 0.3431, -1.3861, -0.6317,  ..., -0.3762, -1.7607, -2.2605],\n",
      "          [ 0.7767, -0.0540, -0.9969,  ..., -0.2887,  0.6609,  1.3682]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8448, -0.7589,  0.6224,  ..., -0.7628, -0.8245, -0.8951],\n",
      "          [-1.1808, -0.6644,  0.5560,  ..., -0.6810, -0.7298, -0.5369],\n",
      "          [-1.0330, -0.7945,  0.4206,  ..., -0.7672, -0.6647, -0.5415],\n",
      "          ...,\n",
      "          [-0.9824, -0.5760,  0.5342,  ..., -0.8527, -0.7582, -0.6278],\n",
      "          [-1.2230, -0.5626,  0.6455,  ..., -0.7480, -0.6114, -0.5572],\n",
      "          [-1.0547, -0.6407,  0.6514,  ..., -0.8553, -0.6424, -0.5035]],\n",
      "\n",
      "         [[-1.1948, -0.0723,  0.3699,  ..., -0.2265, -0.5964,  0.2812],\n",
      "          [-0.4732,  0.3334,  0.0778,  ..., -0.5500, -0.2968,  0.3834],\n",
      "          [-0.3950,  0.2104,  0.4366,  ..., -0.4669, -0.2734,  0.2277],\n",
      "          ...,\n",
      "          [-0.2303,  0.2793,  0.1218,  ..., -0.4874, -0.2210,  0.4718],\n",
      "          [-0.3696,  0.3338,  0.2406,  ..., -0.3924, -0.2252,  0.3019],\n",
      "          [-0.2701,  0.4462,  0.2209,  ..., -0.4106, -0.3309,  0.4160]]],\n",
      "\n",
      "\n",
      "        [[[-0.3270, -0.5662,  0.4947,  ..., -1.1519, -0.7670, -0.9476],\n",
      "          [-1.0365, -0.3990,  0.0101,  ..., -0.8485, -0.8390, -0.4813],\n",
      "          [-1.0715, -0.2390,  0.3010,  ..., -0.8789, -0.7569, -0.5769],\n",
      "          ...,\n",
      "          [-1.1105, -0.4998, -0.0169,  ..., -0.8695, -0.7228, -0.4689],\n",
      "          [-0.7969, -0.4948,  0.2345,  ..., -0.8987, -0.7991, -0.6669],\n",
      "          [-1.0675, -0.4053,  0.1905,  ..., -0.8231, -0.6688, -0.5040]],\n",
      "\n",
      "         [[-0.4199,  0.0013,  0.1295,  ..., -0.2032, -0.8057,  0.6411],\n",
      "          [-0.5322, -0.1042,  0.3122,  ..., -0.1879, -0.4320,  0.7585],\n",
      "          [-0.5491, -0.1301,  0.3139,  ..., -0.1514, -0.4075,  0.8222],\n",
      "          ...,\n",
      "          [-0.3208, -0.1085,  0.1856,  ..., -0.1849, -0.3595,  0.7142],\n",
      "          [-0.2574, -0.1309,  0.3094,  ..., -0.2144, -0.3685,  0.7717],\n",
      "          [-0.4548, -0.0612,  0.2175,  ..., -0.0753, -0.4737,  0.6179]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.8448, -0.7589,  0.6224,  ..., -0.7628, -0.8245, -0.8951],\n",
      "          [-1.1948, -0.0723,  0.3699,  ..., -0.2265, -0.5964,  0.2812]],\n",
      "\n",
      "         [[-1.1808, -0.6644,  0.5560,  ..., -0.6810, -0.7298, -0.5369],\n",
      "          [-0.4732,  0.3334,  0.0778,  ..., -0.5500, -0.2968,  0.3834]],\n",
      "\n",
      "         [[-1.0330, -0.7945,  0.4206,  ..., -0.7672, -0.6647, -0.5415],\n",
      "          [-0.3950,  0.2104,  0.4366,  ..., -0.4669, -0.2734,  0.2277]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9824, -0.5760,  0.5342,  ..., -0.8527, -0.7582, -0.6278],\n",
      "          [-0.2303,  0.2793,  0.1218,  ..., -0.4874, -0.2210,  0.4718]],\n",
      "\n",
      "         [[-1.2230, -0.5626,  0.6455,  ..., -0.7480, -0.6114, -0.5572],\n",
      "          [-0.3696,  0.3338,  0.2406,  ..., -0.3924, -0.2252,  0.3019]],\n",
      "\n",
      "         [[-1.0547, -0.6407,  0.6514,  ..., -0.8553, -0.6424, -0.5035],\n",
      "          [-0.2701,  0.4462,  0.2209,  ..., -0.4106, -0.3309,  0.4160]]],\n",
      "\n",
      "\n",
      "        [[[-0.3270, -0.5662,  0.4947,  ..., -1.1519, -0.7670, -0.9476],\n",
      "          [-0.4199,  0.0013,  0.1295,  ..., -0.2032, -0.8057,  0.6411]],\n",
      "\n",
      "         [[-1.0365, -0.3990,  0.0101,  ..., -0.8485, -0.8390, -0.4813],\n",
      "          [-0.5322, -0.1042,  0.3122,  ..., -0.1879, -0.4320,  0.7585]],\n",
      "\n",
      "         [[-1.0715, -0.2390,  0.3010,  ..., -0.8789, -0.7569, -0.5769],\n",
      "          [-0.5491, -0.1301,  0.3139,  ..., -0.1514, -0.4075,  0.8222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1105, -0.4998, -0.0169,  ..., -0.8695, -0.7228, -0.4689],\n",
      "          [-0.3208, -0.1085,  0.1856,  ..., -0.1849, -0.3595,  0.7142]],\n",
      "\n",
      "         [[-0.7969, -0.4948,  0.2345,  ..., -0.8987, -0.7991, -0.6669],\n",
      "          [-0.2574, -0.1309,  0.3094,  ..., -0.2144, -0.3685,  0.7717]],\n",
      "\n",
      "         [[-1.0675, -0.4053,  0.1905,  ..., -0.8231, -0.6688, -0.5040],\n",
      "          [-0.4548, -0.0612,  0.2175,  ..., -0.0753, -0.4737,  0.6179]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the MaseGraph for the compressed checkpoint to be used in future tutorials for hardware generation and distributed deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
